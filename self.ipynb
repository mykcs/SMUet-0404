{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 7972942,
     "sourceType": "datasetVersion",
     "datasetId": 4691017
    },
    {
     "sourceId": 8062127,
     "sourceType": "datasetVersion",
     "datasetId": 4741616
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pip 安装命令\n",
    "!pip install segmentation-models-pytorch -q\n",
    "# !pip install lightning\n",
    "!pip install wandb -U -q\n",
    "!pip install monai  -q\n",
    "!git clone https://github.com/by-liu/SegLossBias.git  -q\n",
    "!pip install yacs  -q\n",
    "\n",
    "# !pip install ipywidgets\n",
    "# !pip install albumentations\n",
    "# !pip install nibabel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Envirionment Set Up.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 导入的库\n",
    "import sys\n",
    "\n",
    "sys.path.append('/kaggle/working/SegLossBias')\n",
    "\n",
    "import IPython\n",
    "\n",
    "from matplotlib.patches import Patch, Rectangle\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from fastai.losses import *\n",
    "import torchmetrics\n",
    "import wandb\n",
    "# from lightning.pytorch.loggers import WandbLogger\n",
    "from pytorch_lightning.core.mixins import HyperparametersMixin\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "IPython.display.clear_output()\n",
    "\n",
    "print(\"Envirionment Set Up.\")"
   ],
   "metadata": {
    "_uuid": "36007df4-0fc3-4938-9a09-f54d22d06e5f",
    "_cell_guid": "c62342c1-1564-439b-b5f2-8bc2c518bdaf",
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-04-08T09:49:19.941296Z",
     "iopub.execute_input": "2024-04-08T09:49:19.941861Z",
     "iopub.status.idle": "2024-04-08T09:51:10.623901Z",
     "shell.execute_reply.started": "2024-04-08T09:49:19.94183Z",
     "shell.execute_reply": "2024-04-08T09:51:10.62299Z"
    },
    "trusted": true
   },
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset and Augment Setting"
   ],
   "metadata": {
    "_uuid": "5cf48cd2-93fe-4aac-ada9-1a19cd8b2e56",
    "_cell_guid": "0134c009-4039-4716-893f-56425743cab6",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 定义数据增强\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.2),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.RandomRotate90(),\n",
    "    #     A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ElasticTransform(p=0.3, alpha=120, sigma=120 * 0.3, alpha_affine=120 * 0.2),\n",
    "    A.RandomSizedCrop(min_max_height=(128, 256), height=256, width=256, p=0.3),\n",
    "    # A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    # A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "def adjust_window(image, window_center, window_width):\n",
    "    \"\"\"\n",
    "    调整CT图像的窗宽窗位。\n",
    "    :param image: 输入的图像数组。\n",
    "    :param window_center: 窗位（WC）。\n",
    "    :param window_width: 窗宽（WW）。\n",
    "    :return: 调整窗宽窗位后的图像。\n",
    "    \"\"\"\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    windowed_img = np.clip(image, img_min, img_max)\n",
    "    # print(windowed_img.dtype) # NOW its float64\n",
    "    return windowed_img\n",
    "\n",
    "\n",
    "class MultipleImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        \"\"\"\n",
    "        image_paths: 图像文件路径列表\n",
    "        label_paths: 标签文件路径列表\n",
    "        transform: 应用于图像和标签的转换操作\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # 假设图像和标签列表长度相等\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):  # dataloader获取每个数据都会用到这个函数，所以你应当在这里实现你需要的\n",
    "        # 预处理等等步骤\n",
    "        image = (np.load(self.image_paths[idx]))['arr_0']\n",
    "        #         print(image.shape)\n",
    "        label = (np.load(self.label_paths[idx]))['arr_0']\n",
    "        #         print(label.shape)\n",
    "\n",
    "        image = adjust_window(image, window_center=40, window_width=400)\n",
    "\n",
    "        if self.transform:\n",
    "            #             image = image.astype(np.float32)\n",
    "            augmented = self.transform(image=image, mask=label)\n",
    "            image = augmented['image']\n",
    "            #             print(\"image aug\")\n",
    "            label = augmented['mask']\n",
    "            image = image.float()\n",
    "            label = label.long()\n",
    "\n",
    "        label = label.long()\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "        return image.float(), label.long()\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "class MOADataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str, batch_size: int = 16):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.train_transform = train_transform\n",
    "        self.val_transform = val_transform\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        image_dir = os.path.join(self.data_dir, 'image_npz')  # 注意这里路径的更正\n",
    "        label_dir = os.path.join(self.data_dir, 'mask_npz')\n",
    "\n",
    "        # 读取文件路径\n",
    "        image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.npz')])\n",
    "        label_files = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith('.npz')])\n",
    "\n",
    "        # 划分训练集、验证集、测试集\n",
    "        train_size = int(0.8 * len(image_files))\n",
    "        val_size = int(0.1 * len(image_files))\n",
    "\n",
    "        self.train_image_paths = image_files[:train_size]\n",
    "        self.val_image_paths = image_files[train_size:train_size + val_size]\n",
    "        self.test_image_paths = image_files[train_size + val_size:]\n",
    "\n",
    "        self.train_label_paths = label_files[:train_size]\n",
    "        self.val_label_paths = label_files[train_size:train_size + val_size]\n",
    "        self.test_label_paths = label_files[train_size + val_size:]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = MultipleImageDataset(self.train_image_paths, self.train_label_paths,\n",
    "                                             transform=self.train_transform)\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = MultipleImageDataset(self.val_image_paths, self.val_label_paths, transform=self.val_transform)\n",
    "        return DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataset = MultipleImageDataset(self.test_image_paths, self.test_label_paths, transform=self.val_transform)\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "# 定义数据集和数据加载器\n",
    "data_dir = '/kaggle/input/rawniidataset/SMU_Dataset'\n",
    "\n",
    "\n",
    "def predict_and_log_images(num_samples=2):\n",
    "    # 假设 test_loader 和 model 已经定义好了，并且 model 已经移动到了适当的设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    test_loader = data_module.test_dataloader()\n",
    "\n",
    "    # 生成随机索引\n",
    "    indices = torch.randperm(len(test_loader.dataset))[:num_samples]\n",
    "\n",
    "    # 调整subplot的大小\n",
    "    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))  # 每个样本显示3张图（原图、真实掩码、预测掩码）\n",
    "    cmap = plt.get_cmap('tab20')  # 获取颜色映射\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = test_loader.dataset[idx]\n",
    "        class_labels = np.unique(mask)  # 获取类别标签\n",
    "        colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n",
    "        image = image.unsqueeze(0).to(device)  # 添加batch维度并移动到设备\n",
    "        mask = mask.squeeze()  # 移除batch维度（如果有的话）\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(image)\n",
    "            prediction = torch.argmax(pred, dim=1).cpu()  # 获取预测类别并移回CPU\n",
    "\n",
    "        # 显示原始图像\n",
    "        axs[i, 0].imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "        axs[i, 0].set_title(f'Original Image {i + 1}')\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # 显示Ground Truth\n",
    "        axs[i, 1].imshow(mask.cpu().numpy(), cmap='tab20')\n",
    "        axs[i, 1].set_title(f'True Mask {i + 1}')\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        # 显示预测掩码\n",
    "        axs[i, 2].imshow(prediction[0].numpy(), cmap='tab20')\n",
    "        axs[i, 2].set_title(f'Predicted Mask {i + 1}')\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "    legend_elements = [Patch(facecolor=colors[i], label=f'Class {class_labels[i]}') for i in range(len(class_labels))]\n",
    "    fig.legend(handles=legend_elements, loc='upper center', ncol=len(class_labels), title=\"Classes\")\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)  # 防止在notebook中显示图像\n",
    "    return fig\n",
    "\n",
    "\n",
    "class ValidationCallback(Callback):\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # 每10个epoch执行一次\n",
    "        if (trainer.current_epoch + 1) % 5 == 0:\n",
    "            fig = predict_and_log_images(num_samples=2)\n",
    "            # 用wandb记录图像，或进行其他操作\n",
    "            wandb.log({\"Validation Callback Predicted Images\": wandb.Image(fig)})"
   ],
   "metadata": {
    "_uuid": "d3ebdfad-a463-469d-812a-9214d9338d08",
    "_cell_guid": "cfd87ac0-9db7-4743-9831-9f75542fc41c",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-04-07T09:04:15.32179Z",
     "iopub.execute_input": "2024-04-07T09:04:15.322528Z",
     "iopub.status.idle": "2024-04-07T09:04:15.354467Z",
     "shell.execute_reply.started": "2024-04-07T09:04:15.322499Z",
     "shell.execute_reply": "2024-04-07T09:04:15.353546Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (Opt) Data Pre-Check"
   ],
   "metadata": {
    "_uuid": "877d1009-7e88-4dff-8d32-34f278b9ba2f",
    "_cell_guid": "f5aba93a-1cc3-4f13-9763-b1bbe5b31453",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 初始化数据模块\n",
    "data_module = MOADataModule(data_dir=data_dir, batch_size=16)\n",
    "\n",
    "# 设置数据模块（准备数据）\n",
    "data_module.setup()\n",
    "\n",
    "# 获取训练数据加载器\n",
    "train_loader = data_module.train_dataloader()\n",
    "\n",
    "# 从数据加载器中抽取一批数据\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 选择要展示的图像数量\n",
    "num_images_to_show = 4\n",
    "\n",
    "# 创建图表来展示图像和对应的掩码\n",
    "fig, axs = plt.subplots(num_images_to_show, 3, figsize=(15, num_images_to_show * 5))\n",
    "class_labels = np.unique(labels)  # 获取类别标签\n",
    "cmap = plt.get_cmap('tab20')  # 获取颜色映射\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n",
    "\n",
    "for i in range(num_images_to_show):\n",
    "    img = images[i].squeeze().numpy()  # 假设图像和掩码都只有一个通道\n",
    "    lbl = labels[i].squeeze().numpy()\n",
    "    overlay = np.ma.masked_where(lbl == 0, lbl)\n",
    "\n",
    "    axs[i, 0].imshow(img, cmap='gray')\n",
    "    axs[i, 0].set_title('Image')\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    axs[i, 1].imshow(lbl, cmap='tab20')\n",
    "    axs[i, 1].set_title('Mask')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "    axs[i, 2].imshow(img, cmap='gray')\n",
    "    axs[i, 2].imshow(overlay, cmap='tab20', alpha=0.5)\n",
    "    axs[i, 2].set_title('Overlay')\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Label shape: {lbl.shape}\")\n",
    "    print(f\"Image M&m Value: {img.max(), img.min()}\")\n",
    "    print(f\"Label Unique: {np.unique(lbl)}\")\n",
    "\n",
    "legend_elements = [Patch(facecolor=colors[i], label=f'Class {class_labels[i]}') for i in range(len(class_labels))]\n",
    "fig.legend(handles=legend_elements, loc='upper center', ncol=len(class_labels), title=\"Classes\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Show Time!')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T08:56:55.832936Z",
     "iopub.execute_input": "2024-04-07T08:56:55.833339Z",
     "iopub.status.idle": "2024-04-07T08:57:00.089891Z",
     "shell.execute_reply.started": "2024-04-07T08:56:55.833307Z",
     "shell.execute_reply": "2024-04-07T08:57:00.088788Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom DiceCELossWithKL based on SegLossBias\n",
    "https://github.com/by-liu/SegLossBias.git"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from seglossbias.modeling.compound_losses import *\n",
    "from monai.losses.dice import *\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "\n",
    "class DiceCELossWithKL(_Loss):  # 添加KL散度\n",
    "    def __init__(\n",
    "            self,\n",
    "            mode: str = 'MULTICLASS_MODE',\n",
    "            include_background: bool = True,\n",
    "            to_onehot_y: bool = False,\n",
    "            sigmoid: bool = False,\n",
    "            softmax: bool = False,\n",
    "            other_act: Callable | None = None,\n",
    "            squared_pred: bool = False,\n",
    "            jaccard: bool = False,\n",
    "            reduction: str = \"mean\",\n",
    "            smooth_nr: float = 1e-5,\n",
    "            smooth_dr: float = 1e-5,\n",
    "            batch: bool = False,\n",
    "            ce_weight: torch.Tensor | None = None,\n",
    "            weight: torch.Tensor | None = None,\n",
    "            lambda_dice: float = 1.0,\n",
    "            lambda_ce: float = 1.0,\n",
    "            lambda_kl: float = 1.0,  # KL divergence weight\n",
    "            temp: float = 10.0\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.mode = mode  # 设置mode\n",
    "        self.temp = temp  # 设置temp\n",
    "        reduction = look_up_option(reduction, DiceCEReduction).value\n",
    "        weight = ce_weight if ce_weight is not None else weight\n",
    "        dice_weight: torch.Tensor | None\n",
    "        if weight is not None and not include_background:\n",
    "            dice_weight = weight[1:]\n",
    "        else:\n",
    "            dice_weight = weight\n",
    "        self.dice = DiceLoss(\n",
    "            include_background=include_background,\n",
    "            to_onehot_y=to_onehot_y,\n",
    "            sigmoid=sigmoid,\n",
    "            softmax=softmax,\n",
    "            other_act=other_act,\n",
    "            squared_pred=squared_pred,\n",
    "            jaccard=jaccard,\n",
    "            reduction=reduction,\n",
    "            smooth_nr=smooth_nr,\n",
    "            smooth_dr=smooth_dr,\n",
    "            batch=batch,\n",
    "            weight=dice_weight,\n",
    "        )\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(weight=weight, reduction=reduction)\n",
    "        self.binary_cross_entropy = nn.BCEWithLogitsLoss(pos_weight=weight, reduction=reduction)\n",
    "        if lambda_dice < 0.0:\n",
    "            raise ValueError(\"lambda_dice should be no less than 0.0.\")\n",
    "        if lambda_ce < 0.0:\n",
    "            raise ValueError(\"lambda_ce should be no less than 0.0.\")\n",
    "        self.lambda_dice = lambda_dice\n",
    "        self.lambda_ce = lambda_ce\n",
    "        self.old_pt_ver = not pytorch_after(1, 10)\n",
    "        self.lambda_kl = lambda_kl\n",
    "\n",
    "    def ce(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute CrossEntropy loss for the input logits and target.\n",
    "        Will remove the channel dim according to PyTorch CrossEntropyLoss:\n",
    "        https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html?#torch.nn.CrossEntropyLoss.\n",
    "\n",
    "        \"\"\"\n",
    "        n_pred_ch, n_target_ch = input.shape[1], target.shape[1]\n",
    "        if n_pred_ch != n_target_ch and n_target_ch == 1:\n",
    "            target = torch.squeeze(target, dim=1)\n",
    "            target = target.long()\n",
    "        elif self.old_pt_ver:\n",
    "            warnings.warn(\n",
    "                f\"Multichannel targets are not supported in this older Pytorch version {torch.__version__}. \"\n",
    "                \"Using argmax (as a workaround) to convert target to a single channel.\"\n",
    "            )\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        elif not torch.is_floating_point(target):\n",
    "            target = target.to(dtype=input.dtype)\n",
    "\n",
    "        return self.cross_entropy(input, target)  # type: ignore[no-any-return]\n",
    "\n",
    "    def bce(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute Binary CrossEntropy loss for the input logits and target in one single class.\n",
    "\n",
    "        \"\"\"\n",
    "        if not torch.is_floating_point(target):\n",
    "            target = target.to(dtype=input.dtype)\n",
    "\n",
    "        return self.binary_cross_entropy(input, target)  # type: ignore[no-any-return]\n",
    "\n",
    "    def kl_div(self, p, q):\n",
    "        \"\"\" Calculate KL divergence \"\"\"\n",
    "        kl = p * torch.log((p + 1e-10) / (q + 1e-10))\n",
    "        return kl.sum()\n",
    "\n",
    "    def convert_to_one_hot(self, targets, num_classes):\n",
    "        targets = torch.squeeze(targets, dim=1)\n",
    "\n",
    "        # 转换为one-hot [batch_size, height, width, num_classes]\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=num_classes)\n",
    "\n",
    "        # 转置维度以匹配输出 [batch_size, num_classes, height, width]\n",
    "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2)\n",
    "\n",
    "        return targets_one_hot\n",
    "\n",
    "    def calculate_gt_proportion(self, targets_one_hot):\n",
    "        # targets_one_hot: [batch_size, num_classes, height, width]\n",
    "        # 计算每个类别的总像素数\n",
    "        class_totals = targets_one_hot.sum(dim=[0, 2, 3])  # 按照批次和空间维度聚合\n",
    "\n",
    "        # 避免除以零，使用一个小的epsilon\n",
    "        epsilon = 1e-8\n",
    "        # 计算每个类别的比例\n",
    "        gt_proportion = class_totals / (class_totals.sum() + epsilon)\n",
    "\n",
    "        return gt_proportion\n",
    "\n",
    "    def calculate_pred_proportion(self, preds):\n",
    "        # preds: [batch_size, num_classes, height, width], 模型输出的概率分布\n",
    "        # 计算每个类别的预测概率总和\n",
    "        pred_totals = preds.sum(dim=[0, 2, 3])  # 按照批次和空间维度聚合\n",
    "\n",
    "        # 避免除以零，使用一个小的epsilon\n",
    "        epsilon = 1e-8\n",
    "        # 计算每个类别的预测概率比例\n",
    "        pred_proportion = pred_totals / (pred_totals.sum() + epsilon)\n",
    "\n",
    "        return pred_proportion\n",
    "\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input: the shape should be BNH[WD].\n",
    "            target: the shape should be BNH[WD] or B1H[WD].\n",
    "\n",
    "        Raises:\n",
    "            ValueError: When number of dimensions for input and target are different.\n",
    "            ValueError: When number of channels for target is neither 1 nor the same as input.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(input.shape) != len(target.shape):\n",
    "            raise ValueError(\n",
    "                \"the number of dimensions for input and target should be the same, \"\n",
    "                f\"got shape {input.shape} and {target.shape}.\"\n",
    "            )\n",
    "\n",
    "        dice_loss = self.dice(input, target)\n",
    "        ce_loss = self.ce(input, target) if input.shape[1] != 1 else self.bce(input, target)\n",
    "        preds = F.softmax(input, dim=1)\n",
    "        # 在你的模型或损失函数中使用\n",
    "        # 假设 num_classes 是你模型输出的类别数\n",
    "        target_one_hot = self.convert_to_one_hot(target, num_classes=input.size(1))\n",
    "        gt_proportion = self.calculate_gt_proportion(target_one_hot)\n",
    "        pred_proportion = self.calculate_pred_proportion(preds)\n",
    "\n",
    "        # Print the values of the losses\n",
    "        #         print(f\"Dice Loss: {dice_loss.item()}\")\n",
    "        #         print(f\"CE Loss: {ce_loss.item()}\")\n",
    "        #         print(f\"KL Divergence Regularizer: {regularizer.item()}\")\n",
    "        kl_loss = self.kl_div(gt_proportion, pred_proportion)\n",
    "\n",
    "        total_loss: torch.Tensor = self.lambda_dice * dice_loss + self.lambda_ce * ce_loss + self.lambda_kl * kl_loss\n",
    "        #         print(f\"gt: {gt_proportion}\")\n",
    "        #         print(f\"pred: {pred_proportion}\")\n",
    "        #         print(f\"kl_loss: {kl_loss}\")\n",
    "        #         print(f\"total_loss: {total_loss}\")\n",
    "        return total_loss\n",
    "\n",
    "# loss = self.loss_fn(outputs, labels.unsqueeze(1))\n",
    "# Images shape: torch.Size([1, 1, 256, 256])\n",
    "# Labels shape: torch.Size([1, 256, 256])\n",
    "# Outputs shape: torch.Size([1, 14, 256, 256])\n",
    "# Labels with unsqueezed dim shape: torch.Size([1, 1, 256, 256])\n",
    "# Predictions shape: torch.Size([1, 256, 256])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T09:52:49.390427Z",
     "iopub.execute_input": "2024-04-08T09:52:49.390904Z",
     "iopub.status.idle": "2024-04-08T09:52:49.553596Z",
     "shell.execute_reply.started": "2024-04-08T09:52:49.390874Z",
     "shell.execute_reply": "2024-04-08T09:52:49.552643Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Setting"
   ],
   "metadata": {
    "_uuid": "612e9ff5-ea09-4a38-bc45-d077638c795f",
    "_cell_guid": "13f85698-ebef-40de-a063-58b836eb7980",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class UNetTestModel(pl.LightningModule, HyperparametersMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder_name='resnet50',\n",
    "            encoder_weights='imagenet',\n",
    "            in_channels=1,\n",
    "            classes=14,\n",
    "            #         loss_fn=monai.losses.FocalLoss(use_softmax=True, to_onehot_y=True, include_background=False),\n",
    "            loss_fn=DiceCELossWithKL(softmax=True, lambda_dice=0.85, lambda_ce=0.15, to_onehot_y=True,\n",
    "                                     include_background=True),\n",
    "            #         loss_fn=monai.losses.DiceCELoss(softmax=True, lambda_dice=0.85, lambda_ce=0.15, to_onehot_y=True),\n",
    "\n",
    "            #         loss_fn=monai.losses.DiceLoss( to_onehot_y=True),\n",
    "            loss_function='DiceCELossWithKL',\n",
    "            learning_rate=3e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        ###################### model #########################\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=classes,\n",
    "            #             decoder_attention_type='scse',\n",
    "        )\n",
    "        ###################### loss ##########################\n",
    "        self.loss_fn = loss_fn\n",
    "        ###################### metrics ######################\n",
    "        #         self.train_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=classes, average='micro', ignore_index=0)\n",
    "        self.val_accuracy_MACRO = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=classes,\n",
    "                                                                       average='macro', ignore_index=0)\n",
    "        self.val_accuracy_micro = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=classes,\n",
    "                                                                       average='micro', ignore_index=0)\n",
    "        self.val_accuracy_classwise = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=classes,\n",
    "                                                                           average='none', ignore_index=0)\n",
    "        self.Dice = torchmetrics.classification.Dice(multiclass=True, num_classes=classes, average='micro',\n",
    "                                                     ignore_index=0)\n",
    "        self.F1 = torchmetrics.classification.MulticlassF1Score(num_classes=classes, average=\"micro\", ignore_index=0)\n",
    "        self.Jaccard = torchmetrics.classification.MulticlassJaccardIndex(num_classes=classes, average=\"micro\",\n",
    "                                                                          ignore_index=0)\n",
    "\n",
    "    # 定义前向传播\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self.forward(images)\n",
    "        loss = self.loss_fn(outputs, labels.unsqueeze(1))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self.forward(images)\n",
    "        loss = self.loss_fn(outputs, labels.unsqueeze(1))\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        #         print(f\"Images shape: {images.shape}\")\n",
    "        #         print(f\"Labels shape: {labels.shape}\")\n",
    "        #         print(f\"Outputs shape: {outputs.shape}\")\n",
    "        #         print(f\"Labels with unsqueezed dim shape: {labels.unsqueeze(1).shape}\")\n",
    "        #         print(f\"Predictions shape: {preds.shape}\")\n",
    "        #         print(labels_one_hot.shape)\n",
    "        acc_micro = self.val_accuracy_micro(preds, labels)\n",
    "        acc_MACRO = self.val_accuracy_MACRO(preds, labels)\n",
    "        Dice = self.Dice(preds, labels)\n",
    "        F1 = self.F1(preds, labels)\n",
    "        Jaccard = self.Jaccard(preds, labels)\n",
    "        acc = self.val_accuracy_classwise(preds, labels)\n",
    "\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_accuracy_micro', acc_micro, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_accuracy_MACRO', acc_MACRO, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_F1', F1, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_Dice', Dice, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_Jaccard', Jaccard, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "\n",
    "        self.log('val_acc_4', acc[4], on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_acc_5', acc[5], on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_acc_10', acc[10], on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_acc_12', acc[12], on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_acc_13', acc[13], on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "\n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure, **kwargs):\n",
    "        # 调用优化器的step方法前执行自定义操作\n",
    "        # 比如实现学习率热启动\n",
    "        if self.trainer.global_step < 50:\n",
    "            lr_scale = min(1.0, float(self.trainer.global_step + 1) / 50)\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg[\"lr\"] = lr_scale * self.hparams.learning_rate\n",
    "        # 调用优化器的step方法来更新模型参数\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        #         scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9, verbose=True)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0.000001, last_epoch=-1)\n",
    "        #         print(self.hparams.learning_rate)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch',  # 指定更新学习率的间隔单位为'epoch'\n",
    "                'frequency': 1,  # 每个epoch更新一次学习率\n",
    "            }\n",
    "        }"
   ],
   "metadata": {
    "_uuid": "ac36333a-0d4f-494b-a95c-889fc8ca64d9",
    "_cell_guid": "e855577b-fc8c-4409-b4d6-0f82ee37f1d3",
    "execution": {
     "iopub.status.busy": "2024-04-08T09:52:53.712504Z",
     "iopub.execute_input": "2024-04-08T09:52:53.712877Z",
     "iopub.status.idle": "2024-04-08T09:52:53.737328Z",
     "shell.execute_reply.started": "2024-04-08T09:52:53.712847Z",
     "shell.execute_reply": "2024-04-08T09:52:53.736206Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (Opt) Hyper Params Check"
   ],
   "metadata": {
    "_uuid": "7357d769-1c7b-4ae0-b717-68fe4d9524bc",
    "_cell_guid": "f00537a2-4837-4a41-94fe-819c9ce7b959",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = UNetTestModel()\n",
    "print(summary(model, input_size=(1, 1, 256, 256)))\n"
   ],
   "metadata": {
    "_uuid": "54a3656f-6ee2-41bb-92cc-2f278e3ed7d7",
    "_cell_guid": "e6d612dd-14b3-4d64-960e-78b581b1d7e3",
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2024-04-07T06:24:48.246287Z",
     "iopub.execute_input": "2024-04-07T06:24:48.247138Z",
     "iopub.status.idle": "2024-04-07T06:24:49.826754Z",
     "shell.execute_reply.started": "2024-04-07T06:24:48.247107Z",
     "shell.execute_reply": "2024-04-07T06:24:49.825757Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(model.hparams)\n",
    "# def print_model_details(model, indent=0):\n",
    "#     for name, child in model.named_children():\n",
    "#         print(\" \" * indent, name, child)\n",
    "#         print_model_details(child, indent+4)\n",
    "\n",
    "# print_model_details(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install torchviz\n",
    "\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# x = torch.randn(1, 1, 256, 256)  # 生成一个随机输入\n",
    "# y = model(x)\n",
    "# make_dot(y, params=dict(list(model.named_parameters()))).render(\"unet_model\", format=\"png\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-04T05:56:00.287941Z",
     "iopub.execute_input": "2024-04-04T05:56:00.288555Z",
     "iopub.status.idle": "2024-04-04T05:56:29.74728Z",
     "shell.execute_reply.started": "2024-04-04T05:56:00.288505Z",
     "shell.execute_reply": "2024-04-04T05:56:29.746173Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# wandb login"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb_key\")\n",
    "\n",
    "wandb.login(key=secret_value_0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (Opt) Pre-Train Test"
   ],
   "metadata": {
    "_uuid": "7e5a9389-57b6-4a07-b428-b41fcc987525",
    "_cell_guid": "de47c7ee-1eee-4ee1-93f6-d6b43df86981",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_module = MOADataModule(data_dir=data_dir, batch_size=1)\n",
    "# avail test\n",
    "model = UNetTestModel()\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "############################################## fastrun ###################################################\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    fast_dev_run=True,\n",
    "    # callbacks=[lr_monitor, ValidationCallback()],\n",
    "    # check_val_every_n_epoch=10, \n",
    ")\n"
   ],
   "metadata": {
    "_uuid": "3c026544-ec35-408c-9c4a-8840ba0d8202",
    "_cell_guid": "37e59d03-78db-479e-954e-7e8fb28a80a3",
    "execution": {
     "iopub.status.busy": "2024-04-07T06:16:21.886845Z",
     "iopub.execute_input": "2024-04-07T06:16:21.887355Z",
     "iopub.status.idle": "2024-04-07T06:16:26.062713Z",
     "shell.execute_reply.started": "2024-04-07T06:16:21.88732Z",
     "shell.execute_reply": "2024-04-07T06:16:26.061169Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    datamodule=data_module\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "data_module = MOADataModule(data_dir=data_dir, batch_size=1)\n",
    "# learnability test\n",
    "wandb_logger_test = WandbLogger()\n",
    "# # 初始化Trainer，设置overfit_batches来过拟合一小部分数据\n",
    "# lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "test_trainer = pl.Trainer(\n",
    "    overfit_batches=1,\n",
    "    logger=wandb_logger_test,\n",
    "    #                           callbacks=[lr_monitor, ValidationCallback()], \n",
    "    check_val_every_n_epoch=1\n",
    ")\n",
    "\n",
    "# # 或者，使用10个批次的数据来过拟合\n",
    "# test_trainer = pl.Trainer(overfit_batches=10, logger=wandb_logger_test)\n",
    "\"\"\""
   ],
   "metadata": {
    "_uuid": "273bd454-c583-441a-8b86-d5b109f13028",
    "_cell_guid": "4417d2cf-aade-490c-9cf2-4aed7f9bb6f0",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 运行训练\n",
    "test_trainer.fit(\n",
    "    model,\n",
    "    datamodule=data_module\n",
    ")\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sweeps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'},\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'min': 0.0001,\n",
    "            'max': 0.1},\n",
    "        'batch_size': {\n",
    "            'values': [16, 32, 64]}\n",
    "    }\n",
    "}\n",
    "wandb_logger = WandbLogger()\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"test sweeps2\")\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "\n",
    "def sweep_train():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        model = UNetTestModel(\n",
    "            learning_rate=config.learning_rate,\n",
    "            #             batch_size=config.batch_size,\n",
    "            # 其他参数...\n",
    "        )\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=150,\n",
    "            callbacks=[lr_monitor, ValidationCallback()],\n",
    "            logger=wandb_logger,\n",
    "            #             check_val_every_n_epoch=10,\n",
    "            # 其他设置...\n",
    "        )\n",
    "        data_module = MOADataModule(data_dir=data_dir, batch_size=config.batch_size)\n",
    "        trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, function=sweep_train, count=10)\n",
    "\"\"\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-31T04:44:01.362615Z",
     "iopub.execute_input": "2024-03-31T04:44:01.36358Z",
     "iopub.status.idle": "2024-03-31T04:45:17.412101Z",
     "shell.execute_reply.started": "2024-03-31T04:44:01.363541Z",
     "shell.execute_reply": "2024-03-31T04:45:17.410888Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lightning Style Formal Test"
   ],
   "metadata": {
    "_uuid": "8aa9f836-18b6-4afe-8a97-02aa78f1c528",
    "_cell_guid": "db51d23f-6157-4418-9399-1403d782d90e",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "# 假设你已经定义了 LiTSDataModule\n",
    "data_module = MOADataModule(data_dir=data_dir, batch_size=32)\n",
    "# 初始化模型和训练器\n",
    "model = UNetTestModel()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# wandb_logger = WandbLogger(project=\"SMU MOA\", name=\"ResUNetPP50_monaiDiceCELoss_Max150\")\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"UNet_Compare\",\n",
    "    name=\"ResUNet_epo120_DiceCELoss_basicAug\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=120,\n",
    "    #                      fast_dev_run=True, \n",
    "    logger=wandb_logger,\n",
    "    callbacks=[lr_monitor, ValidationCallback()],\n",
    "    #                   callbacks=[lr_monitor],\n",
    "    log_every_n_steps=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    #                   precision='16-mixed',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 创建 Tuner 对象并运行学习率查找"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 创建 Tuner 对象并运行学习率查找\n",
    "tuner = Tuner(trainer)\n",
    "lr_finder = tuner.lr_find(model, datamodule=data_module)\n",
    "\n",
    "# 可视化找到的学习率\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "display(fig)\n",
    "\n",
    "# 将建议的学习率设置给模型\n",
    "# new_lr = lr_finder.suggestion()\n",
    "# model.hparams.learning_rate = new_lr\n",
    "\n",
    "\n",
    "# 注意：在此处，你不需要手动更新 DataLoader 的批量大小\n",
    "# 因为 tuner.scale_batch_size 方法已经更新了 LiTSDataModule 中的 batch_size\n",
    "# 你可以检查更新后的批量大小\n",
    "# tuner.scale_batch_size(model, datamodule=data_module, mode=\"power\")\n",
    "# print(f\"Updated batch size: {data_module.batch_size}\")\n"
   ],
   "metadata": {
    "_uuid": "0049db84-14fe-45a1-aef2-75921b97a7c0",
    "_cell_guid": "02f8ebdf-9845-4e4b-9439-0fbefbf50fbd",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-07T10:26:56.555293Z",
     "iopub.execute_input": "2024-04-07T10:26:56.556121Z",
     "iopub.status.idle": "2024-04-07T11:21:46.719387Z",
     "shell.execute_reply.started": "2024-04-07T10:26:56.556087Z",
     "shell.execute_reply": "2024-04-07T11:21:46.718299Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 使用更新后的学习率继续训练\n",
    "trainer.fit(\n",
    "    model,\n",
    "    datamodule=data_module\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ##################################################### EVA ###################################################\n",
    "# 确保模型处于评估模式\n",
    "model.eval()\n",
    "print(\"eval activated\")\n",
    "\n",
    "# # 循环十次，每次都记录图像\n",
    "for _ in range(10):\n",
    "    fig = predict_and_log_images(num_samples=2)\n",
    "    wandb.log({\"Predicted Images 2\": wandb.Image(fig)})\n",
    "print(\"images logged\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T10:24:44.410233Z",
     "iopub.execute_input": "2024-04-07T10:24:44.411099Z",
     "iopub.status.idle": "2024-04-07T10:24:49.055324Z",
     "shell.execute_reply.started": "2024-04-07T10:24:44.411067Z",
     "shell.execute_reply": "2024-04-07T10:24:49.054637Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def predict_and_log_images(num_samples=2):\n",
    "\n",
    "#     # 假设 test_loader 和 model 已经定义好了，并且 model 已经移动到了适当的设备\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "#     test_loader = data_module.test_dataloader()\n",
    "\n",
    "#     # 生成随机索引\n",
    "#     indices = torch.randperm(len(test_loader.dataset))[:num_samples]\n",
    "#     # 调整subplot的大小\n",
    "#     fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))  # 每个样本显示3张图（原图、真实掩码、预测掩码）\n",
    "\n",
    "#     for i, idx in enumerate(indices):\n",
    "#         image, mask = test_loader.dataset[idx]\n",
    "#         image = image.unsqueeze(0).to(device)  # 添加batch维度并移动到设备\n",
    "#         mask = mask.squeeze()  # 移除batch维度（如果有的话）\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             pred = model(image)\n",
    "#             prediction = torch.argmax(pred, dim=1).cpu()  # 获取预测类别并移回CPU\n",
    "\n",
    "#         # 显示原始图像\n",
    "#         axs[i, 0].imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "#         axs[i, 0].set_title(f'Original Image {i+1}')\n",
    "#         axs[i, 0].axis('off')\n",
    "\n",
    "#         # 显示Ground Truth\n",
    "#         axs[i, 1].imshow(mask.cpu().numpy(), cmap='viridis')\n",
    "#         axs[i, 1].set_title(f'True Mask {i+1}')\n",
    "#         axs[i, 1].axis('off')\n",
    "\n",
    "#         # 显示预测掩码\n",
    "#         axs[i, 2].imshow(prediction[0].numpy(), cmap='viridis')\n",
    "#         axs[i, 2].set_title(f'Predicted Mask {i+1}')\n",
    "#         axs[i, 2].axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.close(fig)  # 防止在notebook中显示图像\n",
    "#     return fig\n",
    "# 循环十次，每次都记录图像\n",
    "# 确保模型处于评估模式\n"
   ],
   "metadata": {
    "_uuid": "ca2de490-a6d3-442b-ae6f-6ec9c9ed6d70",
    "_cell_guid": "b7ef133e-78ff-4942-b372-18d4909f3531",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-07T10:14:47.530173Z",
     "iopub.execute_input": "2024-04-07T10:14:47.530558Z",
     "iopub.status.idle": "2024-04-07T10:15:00.515294Z",
     "shell.execute_reply.started": "2024-04-07T10:14:47.530524Z",
     "shell.execute_reply": "2024-04-07T10:15:00.514196Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 初始化数据模块\n",
    "data_module = MOADataModule(\n",
    "    data_dir='/kaggle/input/rawniidataset/SMU_Dataset',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# 设置数据模块（准备数据）\n",
    "data_module.setup()\n",
    "\n",
    "trainer.validate(\n",
    "    model,\n",
    "    dataloaders=data_module.val_dataloader(),\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "_uuid": "3b5689d1-ff8c-4930-88fa-c9dfa38f5195",
    "_cell_guid": "5725cdac-948a-4953-8a35-18186f67bdb1",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-07T10:19:13.380393Z",
     "iopub.execute_input": "2024-04-07T10:19:13.380769Z",
     "iopub.status.idle": "2024-04-07T10:19:15.569192Z",
     "shell.execute_reply.started": "2024-04-07T10:19:13.380742Z",
     "shell.execute_reply": "2024-04-07T10:19:15.568095Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Following Process (Continual Training)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**if you just finished up training above**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f'{subindent}{f}')\n",
    "\n",
    "\n",
    "# 指定你的目录路径\n",
    "directory_path = '/kaggle/working/UNet Compare/'\n",
    "list_files(directory_path)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T10:10:32.243825Z",
     "iopub.execute_input": "2024-04-07T10:10:32.244801Z",
     "iopub.status.idle": "2024-04-07T10:10:32.253684Z",
     "shell.execute_reply.started": "2024-04-07T10:10:32.244769Z",
     "shell.execute_reply": "2024-04-07T10:10:32.252729Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 创建一个新的Artifact，指定其类型为'model'和Artifact的名称\n",
    "artifact = wandb.Artifact('ResUNet_epo120_DiceCELossWithKL', type='model')\n",
    "artifact.add_file('/kaggle/working/UNet_Compare/w5egg3k9/checkpoints/epoch=119-step=3960.ckpt')\n",
    "\n",
    "# 保存Artifact到wandb\n",
    "wandb.log_artifact(artifact)"
   ],
   "metadata": {
    "_uuid": "51fc1ba5-2cb0-4d6c-9869-a2818e01d7a2",
    "_cell_guid": "ddb49941-070c-4aba-8d7b-d77746b33eea",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-07T10:11:26.496829Z",
     "iopub.execute_input": "2024-04-07T10:11:26.497458Z",
     "iopub.status.idle": "2024-04-07T10:11:28.457988Z",
     "shell.execute_reply.started": "2024-04-07T10:11:26.497428Z",
     "shell.execute_reply": "2024-04-07T10:11:28.456823Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**if you want to continual training from wandb**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.login()\n",
    "artifact_dir = WandbLogger.download_artifact(\n",
    "    artifact=\"southern/UNet Compare/ResUNet_Max120_DiceCELossWithKL_basicAug:v0\")\n",
    "model_ckpt = UNetTestModel.load_from_checkpoint(\n",
    "    '/kaggle/working/artifacts/ResUNet_Max120_DiceCELossWithKL_basicAug:v0/epoch=119-step=3960.ckpt')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T09:53:21.985285Z",
     "iopub.execute_input": "2024-04-08T09:53:21.985997Z",
     "iopub.status.idle": "2024-04-08T09:53:26.063766Z",
     "shell.execute_reply.started": "2024-04-08T09:53:21.985968Z",
     "shell.execute_reply": "2024-04-08T09:53:26.062981Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 定义数据增强\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.2),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.RandomRotate90(),\n",
    "    #     A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.3, alpha_affine=120 * 0.2),\n",
    "    A.RandomSizedCrop(min_max_height=(128, 256), height=256, width=256, p=0.5),\n",
    "    # A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    # A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "def adjust_window(image, window_center, window_width):\n",
    "    \"\"\"\n",
    "    调整CT图像的窗宽窗位。\n",
    "    :param image: 输入的图像数组。\n",
    "    :param window_center: 窗位（WC）。\n",
    "    :param window_width: 窗宽（WW）。\n",
    "    :return: 调整窗宽窗位后的图像。\n",
    "    \"\"\"\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    windowed_img = np.clip(image, img_min, img_max)\n",
    "    # print(windowed_img.dtype) # NOW its float64\n",
    "    return windowed_img\n",
    "\n",
    "\n",
    "class MultipleImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        \"\"\"\n",
    "        image_paths: 图像文件路径列表\n",
    "        label_paths: 标签文件路径列表\n",
    "        transform: 应用于图像和标签的转换操作\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # 假设图像和标签列表长度相等\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):  # dataloader获取每个数据都会用到这个函数，所以你应当在这里实现你需要的\n",
    "        # 预处理等等步骤\n",
    "        image = (np.load(self.image_paths[idx]))['arr_0']\n",
    "        #         print(image.shape)\n",
    "        label = (np.load(self.label_paths[idx]))['arr_0']\n",
    "        #         print(label.shape)\n",
    "\n",
    "        image = adjust_window(image, window_center=40, window_width=400)\n",
    "\n",
    "        if self.transform:\n",
    "            #             image = image.astype(np.float32)\n",
    "            augmented = self.transform(image=image, mask=label)\n",
    "            image = augmented['image']\n",
    "            #             print(\"image aug\")\n",
    "            label = augmented['mask']\n",
    "            image = image.float()\n",
    "            label = label.long()\n",
    "\n",
    "        label = label.long()\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "        return image.float(), label.long()\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "class MOADataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str, batch_size: int = 16):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.train_transform = train_transform\n",
    "        self.val_transform = val_transform\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        image_dir = os.path.join(self.data_dir, 'image_npz')  # 注意这里路径的更正\n",
    "        label_dir = os.path.join(self.data_dir, 'mask_npz')\n",
    "\n",
    "        # 读取文件路径\n",
    "        image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.npz')])\n",
    "        label_files = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith('.npz')])\n",
    "\n",
    "        # 划分训练集、验证集、测试集\n",
    "        train_size = int(0.8 * len(image_files))\n",
    "        val_size = int(0.1 * len(image_files))\n",
    "\n",
    "        self.train_image_paths = image_files[:train_size]\n",
    "        self.val_image_paths = image_files[train_size:train_size + val_size]\n",
    "        self.test_image_paths = image_files[train_size + val_size:]\n",
    "\n",
    "        self.train_label_paths = label_files[:train_size]\n",
    "        self.val_label_paths = label_files[train_size:train_size + val_size]\n",
    "        self.test_label_paths = label_files[train_size + val_size:]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = MultipleImageDataset(self.train_image_paths, self.train_label_paths,\n",
    "                                             transform=self.train_transform)\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = MultipleImageDataset(self.val_image_paths, self.val_label_paths, transform=self.val_transform)\n",
    "        return DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataset = MultipleImageDataset(self.test_image_paths, self.test_label_paths, transform=self.val_transform)\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "# 定义数据集和数据加载器\n",
    "# WARNING: 下面的数据目录是针对特定Kaggle数据集的示例路径。\n",
    "#          请根据您的实际数据集位置修改此路径。\n",
    "data_dir = '/kaggle/input/aug-dataset-for-fine-tune/AUG_dataset'\n",
    "\n",
    "\n",
    "def draw_bounding_boxes(ax, mask, class_ids):\n",
    "    \"\"\" 在给定的轴上绘制边界框，突出显示特定类别 \"\"\"\n",
    "    for class_id in class_ids:\n",
    "        positions = np.argwhere(mask == class_id)\n",
    "        if positions.size > 0:\n",
    "            xmin, xmax = positions[:, 0].min(), positions[:, 0].max()\n",
    "            ymin, ymax = positions[:, 1].min(), positions[:, 1].max()\n",
    "            rect = Rectangle((ymin, xmin), ymax - ymin, xmax - xmin, linewidth=2, edgecolor='red', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(ymin, xmin, f'Class {class_id}', color='red', fontsize=12, va='top', ha='left')\n",
    "\n",
    "\n",
    "def predict_and_log_images(num_samples=2, model=model_ckpt, data_module=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    test_loader = data_module.test_dataloader()\n",
    "\n",
    "    # 生成随机索引\n",
    "    indices = torch.randperm(len(test_loader.dataset))[:num_samples]\n",
    "    special_classes = [4, 5, 10, 12, 13]\n",
    "\n",
    "    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    cmap = plt.get_cmap('tab20')\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = test_loader.dataset[idx]\n",
    "        class_labels = np.unique(mask)\n",
    "        colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        mask = mask.squeeze()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(image)\n",
    "            prediction = torch.argmax(pred, dim=1).cpu().squeeze()\n",
    "\n",
    "        axs[i, 0].imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "        axs[i, 0].set_title(f'Original Image {i + 1}')\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        axs[i, 1].imshow(mask.cpu().numpy(), cmap='tab20')\n",
    "        axs[i, 1].set_title(f'True Mask {i + 1}')\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        axs[i, 2].imshow(prediction.numpy(), cmap='tab20')\n",
    "        axs[i, 2].set_title(f'Predicted Mask {i + 1}')\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "        # 在真实和预测掩码上绘制边界框\n",
    "        draw_bounding_boxes(axs[i, 1], mask.cpu().numpy(), special_classes)\n",
    "        draw_bounding_boxes(axs[i, 2], prediction.numpy(), special_classes)\n",
    "\n",
    "    legend_elements = [Patch(facecolor=colors[i], label=f'Class {class_labels[i]}') for i in range(len(class_labels))]\n",
    "    fig.legend(handles=legend_elements, loc='upper center', ncol=len(class_labels), title=\"Classes\")\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)  # 防止在notebook中显示图像\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "class ValidationCallback(Callback):\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # 每10个epoch执行一次\n",
    "        if (trainer.current_epoch + 1) % 1 == 0:\n",
    "            fig = predict_and_log_images(num_samples=2, model=model_ckpt, data_module=data_module)\n",
    "            # 用wandb记录图像，或进行其他操作\n",
    "            wandb.log({\"Validation Callback Predicted Images\": wandb.Image(fig)})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T10:07:37.011631Z",
     "iopub.execute_input": "2024-04-08T10:07:37.012048Z",
     "iopub.status.idle": "2024-04-08T10:07:37.049128Z",
     "shell.execute_reply.started": "2024-04-08T10:07:37.01202Z",
     "shell.execute_reply": "2024-04-08T10:07:37.048108Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#  初始化数据模块\n",
    "data_module = MOADataModule(data_dir='/kaggle/input/aug-dataset-for-fine-tune/AUG_dataset', batch_size=16)\n",
    "# 设置数据模块（准备数据）\n",
    "data_module.setup()\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ckpt.to(device)\n",
    "model_ckpt.eval()  # 设置为评估模式\n",
    "\n",
    "# 获取测试数据\n",
    "test_loader = data_module.test_dataloader()\n",
    "special_classes = [4, 5, 10, 12, 13]\n",
    "# 取一个批次的数据进行演示\n",
    "for images, masks in test_loader:\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model_ckpt(images)  # 进行预测\n",
    "    predictions = torch.argmax(predictions, dim=1)  # 转换成类别标签\n",
    "    break  # 这里我们只处理一个批次作为示例\n",
    "\n",
    "# 将数据转移到CPU并转换为numpy\n",
    "images = images.cpu().numpy()\n",
    "masks = masks.cpu().numpy()\n",
    "predictions = predictions.cpu().numpy()\n",
    "\n",
    "# 显示图像、真实掩码和预测掩码\n",
    "fig, axs = plt.subplots(len(images), 3, figsize=(20, 5 * len(images)))  # 根据批次大小设置子图\n",
    "class_labels = np.unique(masks)  # 获取类别标签\n",
    "cmap = plt.get_cmap('tab20')  # 获取颜色映射\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n",
    "\n",
    "for i, (img, mask, pred) in enumerate(zip(images, masks, predictions)):\n",
    "    axs[i, 0].imshow(img[0], cmap='gray')  # 假设图片是单通道的\n",
    "    axs[i, 0].set_title('Original Image')\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    axs[i, 1].imshow(mask, cmap=cmap)  # 假设掩码是单通道的\n",
    "    axs[i, 1].set_title('True Mask')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "    axs[i, 2].imshow(pred, cmap=cmap)\n",
    "    axs[i, 2].set_title('Predicted Mask')\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "    draw_bounding_boxes(axs[i, 1], mask, special_classes)\n",
    "    draw_bounding_boxes(axs[i, 2], mask, special_classes)\n",
    "\n",
    "# 创建图例\n",
    "legend_elements = [Patch(facecolor=colors[i], label=f'Class {class_labels[i]}') for i in range(len(class_labels))]\n",
    "fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 1), ncol=len(class_labels),\n",
    "           title=\"Classes\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # 调整子图布局，留出底部空间给图例\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T10:11:35.925941Z",
     "iopub.execute_input": "2024-04-08T10:11:35.926317Z",
     "iopub.status.idle": "2024-04-08T10:11:43.419927Z",
     "shell.execute_reply.started": "2024-04-08T10:11:35.926284Z",
     "shell.execute_reply": "2024-04-08T10:11:43.418868Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# wandb_logger = WandbLogger(project=\"SMU MOA\", name=\"ResUNetPP50_monaiDiceCELoss_Max150\")\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"UNet_Compare\",\n",
    "    name=\"Continual_ResUNet_epo120+120_DiceCELosswithKL_HeavyAug_FreqAug\"\n",
    ")\n",
    "\n",
    "# 设置ModelCheckpoint以每20轮保存一次模型\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='my_model/',  # 模型保存路径\n",
    "    filename='model-{epoch:02d}',  # 文件名包含 epoch\n",
    "    save_top_k=-1,  # 设置为 -1 以保存所有检查点\n",
    "    every_n_epochs=20,  # 每20轮保存一次\n",
    "    save_on_train_epoch_end=True  # 确保在训练轮结束时保存\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "# 假设你已经定义了 LiTSDataModule\n",
    "data_module = MOADataModule(data_dir=data_dir, batch_size=16)\n",
    "# 初始化模型和训练器\n",
    "model = UNetTestModel()\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=120,\n",
    "    # fast_dev_run=True, \n",
    "    logger=wandb_logger,\n",
    "    callbacks=[lr_monitor, checkpoint_callback, ValidationCallback()],\n",
    "    # callbacks=[lr_monitor],\n",
    "    log_every_n_steps=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    # precision='16-mixed',\n",
    ")\n",
    "\n",
    "# 使用更新后的学习率继续训练\n",
    "trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "#  初始化数据模块\n",
    "data_module = MOADataModule(\n",
    "    data_dir='/kaggle/input/aug-dataset-for-fine-tune/AUG_dataset',\n",
    "    batch_size=16\n",
    ")\n",
    "# 设置数据模块（准备数据）\n",
    "data_module.setup()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ckpt.to(device)\n",
    "model_ckpt.eval()  # 设置为评估模式\n",
    "\n",
    "# 获取测试数据\n",
    "test_loader = data_module.test_dataloader()\n",
    "special_classes = [4, 5, 10, 12, 13]\n",
    "# 取一个批次的数据进行演示\n",
    "for images, masks in test_loader:\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model_ckpt(images)  # 进行预测\n",
    "    predictions = torch.argmax(predictions, dim=1)  # 转换成类别标签\n",
    "    break  # 这里我们只处理一个批次作为示例\n",
    "\n",
    "# 将数据转移到CPU并转换为numpy\n",
    "images = images.cpu().numpy()\n",
    "masks = masks.cpu().numpy()\n",
    "predictions = predictions.cpu().numpy()\n",
    "\n",
    "# 显示图像、真实掩码和预测掩码\n",
    "fig, axs = plt.subplots(len(images), 3, figsize=(20, 5 * len(images)))  # 根据批次大小设置子图\n",
    "class_labels = np.unique(masks)  # 获取类别标签\n",
    "cmap = plt.get_cmap('tab20')  # 获取颜色映射\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n",
    "\n",
    "for i, (img, mask, pred) in enumerate(zip(images, masks, predictions)):\n",
    "    axs[i, 0].imshow(img[0], cmap='gray')  # 假设图片是单通道的\n",
    "    axs[i, 0].set_title('Original Image')\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    axs[i, 1].imshow(mask, cmap=cmap)  # 假设掩码是单通道的\n",
    "    axs[i, 1].set_title('True Mask')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "    axs[i, 2].imshow(pred, cmap=cmap)\n",
    "    axs[i, 2].set_title('Predicted Mask')\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "    draw_bounding_boxes(axs[i, 1], mask, special_classes)\n",
    "    draw_bounding_boxes(axs[i, 2], mask, special_classes)\n",
    "\n",
    "# 创建图例\n",
    "legend_elements = [Patch(facecolor=colors[i], label=f'Class {class_labels[i]}') for i in range(len(class_labels))]\n",
    "fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 1), ncol=len(class_labels),\n",
    "           title=\"Classes\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # 调整子图布局，留出底部空间给图例\n",
    "plt.show()\n",
    "wandb.log({\"Predicted Images After Continual Train\": wandb.Image(fig)})\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-08T06:03:01.322885Z",
     "iopub.execute_input": "2024-04-08T06:03:01.323294Z",
     "iopub.status.idle": "2024-04-08T06:03:05.278641Z",
     "shell.execute_reply.started": "2024-04-08T06:03:01.323241Z",
     "shell.execute_reply": "2024-04-08T06:03:05.277748Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
