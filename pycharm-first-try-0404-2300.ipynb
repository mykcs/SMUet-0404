{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 1708009,
     "sourceType": "datasetVersion",
     "datasetId": 958228
    },
    {
     "sourceId": 7972942,
     "sourceType": "datasetVersion",
     "datasetId": 4691017,
     "isSourceIdPinned": false
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Pip 安装命令\n",
    "!pip install segmentation-models-pytorch\n",
    "# !pip install lightning\n",
    "!pip install wandb -U\n",
    "!pip install monai"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:29:18.571911Z",
     "start_time": "2024-04-04T14:29:10.174145Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting segmentation-models-pytorch\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/cb/70/4aac1b240b399b108ce58029ae54bc14497e1bbc275dfab8fd3c84c1e35d/segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m106.7/106.7 kB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: torchvision>=0.5.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.14.1)\r\n",
      "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\r\n",
      "  Using cached pretrainedmodels-0.7.4-py3-none-any.whl\r\n",
      "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\r\n",
      "  Using cached efficientnet_pytorch-0.7.1-py3-none-any.whl\r\n",
      "Collecting timm==0.9.2 (from segmentation-models-pytorch)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/29/90/94f5deb8d76e24a89813aef95e8809ca8fd7414490428480eda19b133d4a/timm-0.9.2-py3-none-any.whl (2.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from segmentation-models-pytorch) (4.66.2)\r\n",
      "Requirement already satisfied: pillow in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from segmentation-models-pytorch) (10.2.0)\r\n",
      "Requirement already satisfied: torch in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1)\r\n",
      "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/56/b3/7c69b37f03260a061883bec0e7b05be7117c1b1c85f5212c72c8c2bc3c8c/munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Requirement already satisfied: pyyaml in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\r\n",
      "Collecting huggingface-hub (from timm==0.9.2->segmentation-models-pytorch)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/05/c0/779afbad8e75565c09ffa24a88b5dd7e293c92b74eb09df6435fc58ac986/huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m388.9/388.9 kB\u001B[0m \u001B[31m58.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting safetensors (from timm==0.9.2->segmentation-models-pytorch)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e2/cb/481d38e53f4096da599a439c0767e818a41a54b7e25a33b50420e10d245e/safetensors-0.4.2-cp38-cp38-macosx_11_0_arm64.whl (392 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m392.9/392.9 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (4.9.0)\r\n",
      "Requirement already satisfied: numpy in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.22.0)\r\n",
      "Requirement already satisfied: requests in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\r\n",
      "Collecting filelock (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/8b/69/acdf492db27dea7be5c63053230130e0574fd8a376de3555d5f8bbc3d3ad/filelock-3.13.3-py3-none-any.whl (11 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/93/6d/66d48b03460768f523da62a57a7e14e5e95fdf339d79e996ce3cecda2cdb/fsspec-2024.3.1-py3-none-any.whl (171 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m172.0/172.0 kB\u001B[0m \u001B[31m27.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.9 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2024.2.2)\r\n",
      "Installing collected packages: safetensors, munch, fsspec, filelock, huggingface-hub, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 filelock-3.13.3 fsspec-2024.3.1 huggingface-hub-0.22.2 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.4.2 segmentation-models-pytorch-0.3.3 timm-0.9.2\r\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: wandb in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (0.16.5)\r\n",
      "Collecting wandb\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/8b/8d/bb05a4ecdeac6b2256d98ac10bae8723af5d7a8c1a4c2384b3ae0f80370e/wandb-0.16.6-py3-none-any.whl (2.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (3.1.43)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (2.31.0)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (5.9.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (1.44.0)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: PyYAML in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (6.0.1)\r\n",
      "Requirement already satisfied: setproctitle in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (68.2.2)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (1.4.4)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (4.9.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from wandb) (4.25.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n",
      "Installing collected packages: wandb\r\n",
      "  Attempting uninstall: wandb\r\n",
      "    Found existing installation: wandb 0.16.5\r\n",
      "    Uninstalling wandb-0.16.5:\r\n",
      "      Successfully uninstalled wandb-0.16.5\r\n",
      "Successfully installed wandb-0.16.6\r\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting monai\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/08/94/e8a7ba00dd0c7ce959648b562043bd22125d65f5e519e566c822f71bc437/monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.20 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from monai) (1.22.0)\r\n",
      "Requirement already satisfied: torch>=1.9 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from monai) (1.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from torch>=1.9->monai) (4.9.0)\r\n",
      "Installing collected packages: monai\r\n",
      "Successfully installed monai-1.3.0\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting lightning\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a0/4a/b7d4f62449d940ce43d4657322a14f5718815b648f9d2b0b23a195acb646/lightning-2.2.1-py3-none-any.whl (2.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from lightning) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.3.1)\r\n",
      "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/5e/9e/e7768a8e363fc6f0c978bb7a0aa7641f10d80be60000e788ef2f01d34a7c/lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from lightning) (1.22.0)\r\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from lightning) (23.2)\r\n",
      "Requirement already satisfied: torch<4.0,>=1.13.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from lightning) (1.13.1)\r\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f3/0e/cedcb9c8aeb2d1f655f8d05f841b14d84b0a68d9f31afae4af55c7c6d0a9/torchmetrics-1.3.2-py3-none-any.whl (841 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m841.5/841.5 kB\u001B[0m \u001B[31m21.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from lightning) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from lightning) (4.9.0)\r\n",
      "Collecting pytorch-lightning (from lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/56/ed/192d7518b15a06452f480346eeebe1d1d4595af80687e142b2e6f18539fd/pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m801.6/801.6 kB\u001B[0m \u001B[31m18.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2025.0,>=2022.5.0->lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f5/7a/17492df8e51df785f709e9adf9085f0919d1e19ee3495d2db24449dd17cc/aiohttp-3.9.3-cp38-cp38-macosx_11_0_arm64.whl (389 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m389.4/389.4 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: setuptools in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (68.2.2)\r\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.1.0)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a0/9f/255b4d34a4f8ff7f31db79406917c403032aa19b39a651ad0a0d6b467317/frozenlist-1.4.1-cp38-cp38-macosx_11_0_arm64.whl (53 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.8/53.8 kB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7b/0a/c5a12e908f32ec3844772a8a52322594bfc7ea5786ffdfd4efc70eead079/multidict-6.0.5-cp38-cp38-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/fc/ca/33754d12ecbe4ccb677353f4e1c7ce3ea748cc5ab9f435535ebf3bf7ac8c/yarl-1.9.4-cp38-cp38-macosx_11_0_arm64.whl (82 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m82.0/82.0 kB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\r\n",
      "Requirement already satisfied: idna>=2.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.4)\r\n",
      "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, torchmetrics, aiosignal, aiohttp, pytorch-lightning, lightning\r\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 lightning-2.2.1 lightning-utilities-0.11.2 multidict-6.0.5 pytorch-lightning-2.2.1 torchmetrics-1.3.2 yarl-1.9.4\r\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install lightning\n",
    "/kaggle/input/brats2018"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:33:37.168142Z",
     "start_time": "2024-04-04T14:33:29.964763Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: nibabel in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (5.2.1)\r\n",
      "Requirement already satisfied: importlib-resources>=1.3 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from nibabel) (6.1.1)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from nibabel) (1.22.0)\r\n",
      "Requirement already satisfied: packaging>=17 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from nibabel) (23.2)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from importlib-resources>=1.3->nibabel) (3.17.0)\r\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting albumentations\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/40/01/4202bd81ab337dca5693d7d1cb25c8e9041d97762aee738a24382ff9af2f/albumentations-1.4.3-py3-none-any.whl (137 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m137.0/137.0 kB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting numpy>=1.24.4 (from albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a7/ae/f53b7b265fdc701e663fbb322a8e9d4b14d9cb7b2385f45ddfabfc4327e4/numpy-1.24.4-cp38-cp38-macosx_11_0_arm64.whl (13.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting scipy>=1.10.0 (from albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/93/4a/50c436de1353cce8b66b26e49a687f10b91fe7465bf34e4565d810153003/scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl (28.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m28.8/28.8 MB\u001B[0m \u001B[31m13.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting scikit-image>=0.21.0 (from albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/62/9b/8fd51371f3fd4ce06092d1f4740ec5a874a996727117e076c03755e8c777/scikit_image-0.21.0-cp38-cp38-macosx_12_0_arm64.whl (12.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.3/12.3 MB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: PyYAML in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from albumentations) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from albumentations) (4.9.0)\r\n",
      "Collecting scikit-learn>=1.3.2 (from albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a4/62/92e9cec3deca8b45abf62dd8f6469d688b3f28b9c170809fcc46f110b523/scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl (9.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.4/9.4 MB\u001B[0m \u001B[31m12.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting opencv-python-headless>=4.9.0 (from albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/32/0c/a59f2a40d6058ee8126668dc5dff6977c913f6ecd21dbd15b41563409a18/opencv_python_headless-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m35.4/35.4 MB\u001B[0m \u001B[31m13.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting networkx>=2.8 (from scikit-image>=0.21.0->albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a8/05/9d4f9b78ead6b2661d6e8ea772e111fc4a9fbd866ad0c81906c11206b55e/networkx-3.1-py3-none-any.whl (2.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pillow>=9.0.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from scikit-image>=0.21.0->albumentations) (10.2.0)\r\n",
      "Collecting imageio>=2.27 (from scikit-image>=0.21.0->albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/02/25/66533a8390e3763cf8254dee143dbf8a830391ea60d2762512ba7f9ddfbe/imageio-2.34.0-py3-none-any.whl (313 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m313.4/313.4 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/06/a3/68d17088a4f09565bc7341fd20490da8191ec4cddde479daaabbe07bb603/tifffile-2023.7.10-py3-none-any.whl (220 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m220.9/220.9 kB\u001B[0m \u001B[31m15.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting PyWavelets>=1.1.1 (from scikit-image>=0.21.0->albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/73/8c/6d50b8e2ee4d12373a63791ad742df1e30ddd5f0f8d1c000c5b6b3afb2c9/PyWavelets-1.4.1-cp38-cp38-macosx_11_0_arm64.whl (4.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.3/4.3 MB\u001B[0m \u001B[31m13.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: packaging>=21 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from scikit-image>=0.21.0->albumentations) (23.2)\r\n",
      "Collecting lazy_loader>=0.2 (from scikit-image>=0.21.0->albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a1/c3/65b3814e155836acacf720e5be3b5757130346670ac454fee29d3eda1381/lazy_loader-0.3-py3-none-any.whl (9.1 kB)\r\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=1.3.2->albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl (302 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m302.2/302.2 kB\u001B[0m \u001B[31m11.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn>=1.3.2->albumentations)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/1e/84/ccd9b08653022b7785b6e3ee070ffb2825841e0dc119be22f0840b2b35cb/threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\r\n",
      "Installing collected packages: threadpoolctl, numpy, networkx, lazy_loader, joblib, tifffile, scipy, PyWavelets, opencv-python-headless, imageio, scikit-learn, scikit-image, albumentations\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.22.0\r\n",
      "    Uninstalling numpy-1.22.0:\r\n",
      "      Successfully uninstalled numpy-1.22.0\r\n",
      "Successfully installed PyWavelets-1.4.1 albumentations-1.4.3 imageio-2.34.0 joblib-1.3.2 lazy_loader-0.3 networkx-3.1 numpy-1.24.3 opencv-python-headless-4.9.0.80 scikit-image-0.21.0 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.4.0 tifffile-2023.7.10\r\n"
     ]
    }
   ],
   "source": [
    "! pip install nibabel\n",
    "! pip install albumentations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:35:09.841693Z",
     "start_time": "2024-04-04T14:34:50.861321Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting fastai\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/79/ab/70ca55249e17b735af0dde65d9844392b8705260521b91d04286ba87a9e5/fastai-2.7.14-py3-none-any.whl (232 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m232.2/232.2 kB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pip in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (23.3.1)\r\n",
      "Requirement already satisfied: packaging in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (23.2)\r\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/47/60/ed35253a05a70b63e4f52df1daa39a6a464a3e22b0bd060b77f63e2e2b6a/fastdownload-0.0.7-py3-none-any.whl (12 kB)\r\n",
      "Collecting fastcore<1.6,>=1.5.29 (from fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/39/b8/3059245adb5e4421222aab3852ac7f47d68eba82c8c62b88928ec1c69431/fastcore-1.5.29-py3-none-any.whl (67 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.6/67.6 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: torchvision>=0.11 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (0.14.1)\r\n",
      "Requirement already satisfied: matplotlib in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (3.7.2)\r\n",
      "Collecting pandas (from fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/53/c3/f8e87361f7fdf42012def602bfa2a593423c729f5cb7c97aed7f51be66ac/pandas-2.0.3-cp38-cp38-macosx_11_0_arm64.whl (10.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.7/10.7 MB\u001B[0m \u001B[31m21.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (6.0.1)\r\n",
      "Collecting fastprogress>=0.2.4 (from fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a7/8f/213223fdee199c55db81e2d0c669f30e8285c5be2526c4ed924de39247da/fastprogress-1.0.3-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (10.2.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (1.3.2)\r\n",
      "Requirement already satisfied: scipy in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (1.10.1)\r\n",
      "Collecting spacy<4 (from fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4f/bd/5dd19c5fdc4f43201567122c60aa7e884a221e6002d9f9c07664aa7e00c7/spacy-3.7.4-cp38-cp38-macosx_11_0_arm64.whl (6.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.6/6.6 MB\u001B[0m \u001B[31m19.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: torch<2.3,>=1.10 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from fastai) (1.13.1)\r\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\r\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\r\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/9e/fd/d3bb50b560aebb6d7b0eeeff28d1c1af9a03116865ee18daee0607633f0d/murmurhash-1.0.10-cp38-cp38-macosx_11_0_arm64.whl (26 kB)\r\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c3/90/536f88369ae2904021e7b32ec0e2b73aab1942ceb2c4916d707605b969b4/cymem-2.0.8-cp38-cp38-macosx_11_0_arm64.whl (41 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m41.9/41.9 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting preshed<3.1.0,>=3.0.2 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/13/88/9ed5c9e1eff13ee64544dec8f4fd2c5bfa17f9d06d039fb7dfb6c8f23f55/preshed-3.0.9-cp38-cp38-macosx_11_0_arm64.whl (131 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m131.0/131.0 kB\u001B[0m \u001B[31m9.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting thinc<8.3.0,>=8.2.2 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3f/7c/aeda4dc216bab0a07ad50d9546e85e60d48e5d35a9805687b65e087a7343/thinc-8.2.3-cp38-cp38-macosx_11_0_arm64.whl (781 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m781.1/781.1 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting wasabi<1.2.0,>=0.9.1 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl (27 kB)\r\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d2/dc/36bff7e940e26c6ca0b4c1ece905463b04530a2bdbc266d3e1f18ef30428/srsly-2.4.8-cp38-cp38-macosx_11_0_arm64.whl (489 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m489.6/489.6 kB\u001B[0m \u001B[31m33.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting catalogue<2.1.0,>=2.0.6 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl (17 kB)\r\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d5/e5/b63b8e255d89ba4155972990d42523251d4d1368c4906c646597f63870e2/weasel-0.3.4-py3-none-any.whl (50 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.1/50.1 kB\u001B[0m \u001B[31m5.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting typer<0.10.0,>=0.3.0 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/62/39/82c9d3e10979851847361d922a373bdfef4091020da7f893acfaf07c0225/typer-0.9.4-py3-none-any.whl (45 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting smart-open<7.0.0,>=5.2.1 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.0/57.0 kB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from spacy<4->fastai) (4.66.2)\r\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e5/f3/8296f550276194a58c5500d55b19a27ae0a5a3a51ffef66710c58544b32d/pydantic-2.6.4-py3-none-any.whl (394 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m394.9/394.9 kB\u001B[0m \u001B[31m35.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from spacy<4->fastai) (3.1.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from spacy<4->fastai) (68.2.2)\r\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/fe/c3/0d04d248624a181e57c2870127dfa8d371973561caf54333c85e8f9133a2/langcodes-3.3.0-py3-none-any.whl (181 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m181.6/181.6 kB\u001B[0m \u001B[31m22.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.15.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from spacy<4->fastai) (1.24.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests->fastai) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests->fastai) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests->fastai) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from requests->fastai) (2024.2.2)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from torch<2.3,>=1.10->fastai) (4.9.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from matplotlib->fastai) (1.0.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from matplotlib->fastai) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from matplotlib->fastai) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from matplotlib->fastai) (1.4.4)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from matplotlib->fastai) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from matplotlib->fastai) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from matplotlib->fastai) (6.1.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from pandas->fastai) (2023.3.post1)\r\n",
      "Collecting tzdata>=2022.1 (from pandas->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl (345 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m345.4/345.4 kB\u001B[0m \u001B[31m28.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: joblib>=1.1.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from scikit-learn->fastai) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from scikit-learn->fastai) (3.4.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->fastai) (3.17.0)\r\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl (12 kB)\r\n",
      "Collecting pydantic-core==2.16.3 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f0/d6/a8914af00eeb62444609f3c7acda8fd92b23ed5f14d272ad0f3fbe103730/pydantic_core-2.16.3-cp38-cp38-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m10.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: six>=1.5 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\r\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/71/b8/e90fd4c2c4e14335da99b33d3e022527e2b67e15194c2c678d04ad091b2d/blis-0.7.11-cp38-cp38-macosx_11_0_arm64.whl (1.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m9.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/39/78/f9d18da7b979a2e6007bfcea2f3c8cc02ed210538ae1ce7e69092aed7b18/confection-0.1.4-py3-none-any.whl (35 kB)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai) (8.1.7)\r\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy<4->fastai)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/0f/6e/45b57a7d4573d85d0b0a39d99673dc1f5eea9d92a1a4603b35e968fbf89a/cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.0/45.0 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/myk/anaconda3/envs/seg-test-0401/lib/python3.8/site-packages (from jinja2->spacy<4->fastai) (2.1.3)\r\n",
      "Installing collected packages: cymem, wasabi, tzdata, typer, spacy-loggers, spacy-legacy, smart-open, pydantic-core, murmurhash, langcodes, fastprogress, fastcore, cloudpathlib, catalogue, blis, annotated-types, srsly, pydantic, preshed, pandas, fastdownload, confection, weasel, thinc, spacy, fastai\r\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 fastai-2.7.14 fastcore-1.5.29 fastdownload-0.0.7 fastprogress-1.0.3 langcodes-3.3.0 murmurhash-1.0.10 pandas-2.0.3 preshed-3.0.9 pydantic-2.6.4 pydantic-core-2.16.3 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 tzdata-2024.1 wasabi-1.1.2 weasel-0.3.4\r\n"
     ]
    }
   ],
   "source": [
    "! pip install fastai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:36:28.420850Z",
     "start_time": "2024-04-04T14:36:13.718487Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# 导入的库\n",
    "import IPython\n",
    "import albumentations as A\n",
    "import monai\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import wandb\n",
    "from IPython.display import display\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "# from lightning.pytorch.loggers import WandbLogger\n",
    "from pytorch_lightning.core.mixins import HyperparametersMixin\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "IPython.display.clear_output()\n",
    "\n",
    "print(\"Envirionment Set Up.\")"
   ],
   "metadata": {
    "_uuid": "36007df4-0fc3-4938-9a09-f54d22d06e5f",
    "_cell_guid": "c62342c1-1564-439b-b5f2-8bc2c518bdaf",
    "execution": {
     "iopub.status.busy": "2024-04-03T15:46:40.498041Z",
     "iopub.execute_input": "2024-04-03T15:46:40.498460Z",
     "iopub.status.idle": "2024-04-03T15:47:54.004163Z",
     "shell.execute_reply.started": "2024-04-03T15:46:40.498425Z",
     "shell.execute_reply": "2024-04-03T15:47:54.003221Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Envirionment Set Up.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset and Augment Setting"
   ],
   "metadata": {
    "_uuid": "5cf48cd2-93fe-4aac-ada9-1a19cd8b2e56",
    "_cell_guid": "0134c009-4039-4716-893f-56425743cab6",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 定义数据增强\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(),\n",
    "    A.ElasticTransform(p=0.3, alpha=120, sigma=120 * 0.08, alpha_affine=120 * 0.015),\n",
    "    A.RandomSizedCrop(min_max_height=(128, 256), height=256, width=256, p=0.3),\n",
    "    # A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    # A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2(),\n",
    "])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T15:47:59.471255Z",
     "iopub.execute_input": "2024-04-03T15:47:59.472421Z",
     "iopub.status.idle": "2024-04-03T15:47:59.480969Z",
     "shell.execute_reply.started": "2024-04-03T15:47:59.472385Z",
     "shell.execute_reply": "2024-04-03T15:47:59.479314Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:40:09.747885Z",
     "start_time": "2024-04-04T14:40:09.744895Z"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/np/lwj6dcgj7vgbzkyrpwn082pr0000gn/T/ipykernel_56485/3205421908.py:8: DeprecationWarning: Initializing with 'height' and 'width' is deprecated. Please use a tuple (height, width) for the 'size' argument.\n",
      "  A.RandomSizedCrop(min_max_height=(128, 256), height=256, width=256, p=0.3),\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def adjust_window(image, window_center, window_width):\n",
    "    \"\"\"\n",
    "    调整CT图像的窗宽窗位。\n",
    "    :param image: 输入的图像数组。\n",
    "    :param window_center: 窗位（WC）。\n",
    "    :param window_width: 窗宽（WW）。\n",
    "    :return: 调整窗宽窗位后的图像。\n",
    "    \"\"\"\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    windowed_img = np.clip(image, img_min, img_max)\n",
    "    # print(windowed_img.dtype) # NOW its float64\n",
    "    return windowed_img\n",
    "\n",
    "\n",
    "class MultipleImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        \"\"\"\n",
    "        image_paths: 图像文件路径列表\n",
    "        label_paths: 标签文件路径列表\n",
    "        transform: 应用于图像和标签的转换操作\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # 假设图像和标签列表长度相等\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):  # dataloader获取每个数据都会用到这个函数，所以你应当在这里实现你需要的\n",
    "        # 预处理等等步骤\n",
    "        image = (np.load(self.image_paths[idx]))['arr_0']\n",
    "        #         print(image.shape)\n",
    "        label = (np.load(self.label_paths[idx]))['arr_0']\n",
    "        #         print(label.shape)\n",
    "\n",
    "        image = adjust_window(image, window_center=40, window_width=400)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=label)\n",
    "            image = augmented['image']\n",
    "            #             print(\"image aug\")\n",
    "            label = augmented['mask']\n",
    "            image = image.float()\n",
    "            label = label.long()\n",
    "\n",
    "        label = label.long()\n",
    "        # normalize image here based on its value accordingly\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "        # print(image.unique())\n",
    "        #         print(f\"label shape: {label.shape}\")\n",
    "        #         print(image.shape)\n",
    "        return image.float(), label.long()\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "class MOADataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str, batch_size: int = 16):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.train_transform = train_transform\n",
    "        self.val_transform = val_transform\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        image_dir = os.path.join(self.data_dir, 'image_npz')  # 注意这里路径的更正\n",
    "        label_dir = os.path.join(self.data_dir, 'mask_npz')\n",
    "\n",
    "        # 读取文件路径\n",
    "        image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.npz')])\n",
    "        label_files = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith('.npz')])\n",
    "\n",
    "        # 划分训练集、验证集、测试集\n",
    "        train_size = int(0.8 * len(image_files))\n",
    "        val_size = int(0.1 * len(image_files))\n",
    "\n",
    "        self.train_image_paths = image_files[:train_size]\n",
    "        self.val_image_paths = image_files[train_size:train_size + val_size]\n",
    "        self.test_image_paths = image_files[train_size + val_size:]\n",
    "\n",
    "        self.train_label_paths = label_files[:train_size]\n",
    "        self.val_label_paths = label_files[train_size:train_size + val_size]\n",
    "        self.test_label_paths = label_files[train_size + val_size:]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = MultipleImageDataset(self.train_image_paths, self.train_label_paths,\n",
    "                                             transform=self.train_transform)\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = MultipleImageDataset(self.val_image_paths, self.val_label_paths, transform=self.val_transform)\n",
    "        return DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataset = MultipleImageDataset(self.test_image_paths, self.test_label_paths, transform=self.val_transform)\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "# 定义数据集和数据加载器\n",
    "# data_dir = '/kaggle/input/brats2018'\n",
    "data_dir = 'kaggle/input/rawniidataset/SMU_Dataset'\n",
    "\n",
    "\n",
    "def predict_and_log_images(num_samples=2):\n",
    "    # 假设 test_loader 和 model 已经定义好了，并且 model 已经移动到了适当的设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    test_loader = data_module.test_dataloader()\n",
    "\n",
    "    # 生成随机索引\n",
    "    indices = torch.randperm(len(test_loader.dataset))[:num_samples]\n",
    "    # 调整subplot的大小\n",
    "    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))  # 每个样本显示3张图（原图、真实掩码、预测掩码）\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = test_loader.dataset[idx]\n",
    "        image = image.unsqueeze(0).to(device)  # 添加batch维度并移动到设备\n",
    "        mask = mask.squeeze()  # 移除batch维度（如果有的话）\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(image)\n",
    "            prediction = torch.argmax(pred, dim=1).cpu()  # 获取预测类别并移回CPU\n",
    "\n",
    "        # 显示原始图像\n",
    "        axs[i, 0].imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "        axs[i, 0].set_title(f'Original Image {i + 1}')\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # 显示Ground Truth\n",
    "        axs[i, 1].imshow(mask.cpu().numpy(), cmap='gray')\n",
    "        axs[i, 1].set_title(f'True Mask {i + 1}')\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        # 显示预测掩码\n",
    "        axs[i, 2].imshow(prediction[0].numpy(), cmap='gray')\n",
    "        axs[i, 2].set_title(f'Predicted Mask {i + 1}')\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)  # 防止在notebook中显示图像\n",
    "    return fig\n",
    "\n",
    "\n",
    "# 自定义回调，用于在验证结束时执行操作\n",
    "class ValidationCallback(Callback):\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        print(\"Validation epoch ended. Executing custom actions...\")\n",
    "        # 假设test_loader已经在pl_module（即您的model）中定义\n",
    "        # 或者您可以在这里直接访问datamodule的test_dataloader\n",
    "        #         test_loader = pl_module.test_dataloader()\n",
    "\n",
    "        # 确保模型处于评估模式\n",
    "        #         pl_module.eval()\n",
    "        #         print(\"eval activated\")\n",
    "\n",
    "        # 执行自定义的预测和绘图逻辑\n",
    "        fig = predict_and_log_images(num_samples=2)\n",
    "        # 用wandb记录图像，或进行其他操作\n",
    "        wandb.log({\"Validation Callback Predicted Images\": wandb.Image(fig)})"
   ],
   "metadata": {
    "_uuid": "d3ebdfad-a463-469d-812a-9214d9338d08",
    "_cell_guid": "cfd87ac0-9db7-4743-9831-9f75542fc41c",
    "collapsed": false,
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-04-03T15:48:03.703293Z",
     "iopub.execute_input": "2024-04-03T15:48:03.703853Z",
     "iopub.status.idle": "2024-04-03T15:48:03.743614Z",
     "shell.execute_reply.started": "2024-04-03T15:48:03.703804Z",
     "shell.execute_reply": "2024-04-03T15:48:03.742021Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:55:30.761893Z",
     "start_time": "2024-04-04T14:55:30.751217Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (Opt) Data Pre-Check"
   ],
   "metadata": {
    "_uuid": "877d1009-7e88-4dff-8d32-34f278b9ba2f",
    "_cell_guid": "f5aba93a-1cc3-4f13-9763-b1bbe5b31453",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 初始化数据模块\n",
    "data_module = MOADataModule(data_dir='kaggle/input/rawniidataset/SMU_Dataset', batch_size=16)\n",
    "# data_module = MOADataModule(data_dir='/kaggle/input/brats2018', batch_size=16)\n",
    "\n",
    "\n",
    "# 设置数据模块（准备数据）\n",
    "data_module.setup()\n",
    "\n",
    "# 获取训练数据加载器\n",
    "train_loader = data_module.train_dataloader()\n",
    "\n",
    "# 从数据加载器中抽取一批数据\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 选择要展示的图像数量\n",
    "num_images_to_show = 4\n",
    "\n",
    "# 创建图表来展示图像和对应的掩码\n",
    "fig, axs = plt.subplots(num_images_to_show, 3, figsize=(15, num_images_to_show * 5))\n",
    "\n",
    "for i in range(num_images_to_show):\n",
    "    img = images[i].squeeze().numpy()  # 假设图像和掩码都只有一个通道\n",
    "    lbl = labels[i].squeeze().numpy()\n",
    "    overlay = np.ma.masked_where(lbl == 0, lbl)\n",
    "\n",
    "    axs[i, 0].imshow(img, cmap='gray')\n",
    "    axs[i, 0].set_title('Image')\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    axs[i, 1].imshow(lbl, cmap='gray')\n",
    "    axs[i, 1].set_title('Mask')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "    axs[i, 2].imshow(img, cmap='gray')\n",
    "    axs[i, 2].imshow(overlay, cmap='autumn', alpha=0.5)\n",
    "    axs[i, 2].set_title('Overlay')\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Label shape: {lbl.shape}\")\n",
    "    print(f\"Image M&m Value: {img.max(), img.min()}\")\n",
    "    print(f\"Label Unique: {np.unique(lbl)}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Show Time!')"
   ],
   "metadata": {
    "_uuid": "5ed77956-2d29-4ad9-a5d9-5dde6b33a2e9",
    "_cell_guid": "21a0fb7b-2f3c-446b-96cf-4e998b9970d8",
    "_kg_hide-input": false,
    "execution": {
     "iopub.status.busy": "2024-04-03T15:48:08.604931Z",
     "iopub.execute_input": "2024-04-03T15:48:08.605345Z",
     "iopub.status.idle": "2024-04-03T15:48:09.343757Z",
     "shell.execute_reply.started": "2024-04-03T15:48:08.605311Z",
     "shell.execute_reply": "2024-04-03T15:48:09.342160Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Setting"
   ],
   "metadata": {
    "_uuid": "612e9ff5-ea09-4a38-bc45-d077638c795f",
    "_cell_guid": "13f85698-ebef-40de-a063-58b836eb7980",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        #         print(f\"x1 Shape is: {x1.shape}\")\n",
    "        #         print(f\"x2 Shape is: {x2.shape}\")\n",
    "        #         print(f\"x Shape is: {x.shape}\")\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=1, n_classes=14, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #         print(f\"Input shape: {x.shape}\")\n",
    "        x1 = self.inc(x)\n",
    "        #         print(f\"After inc (DoubleConv): {x1.shape}\")\n",
    "        x2 = self.down1(x1)\n",
    "        #         print(f\"After down1: {x2.shape}\")\n",
    "        x3 = self.down2(x2)\n",
    "        #         print(f\"After down2: {x3.shape}\")\n",
    "        x4 = self.down3(x3)\n",
    "        #         print(f\"After down3: {x4.shape}\")\n",
    "        x5 = self.down4(x4)\n",
    "        #         print(f\"After down4: {x5.shape}\")\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        #         print(f\"After up1 (with skip connection from down3): {x.shape}\")\n",
    "        x = self.up2(x, x3)\n",
    "        #         print(f\"After up2 (with skip connection from down2): {x.shape}\")\n",
    "        x = self.up3(x, x2)\n",
    "        #         print(f\"After up3 (with skip connection from down1): {x.shape}\")\n",
    "        x = self.up4(x, x1)\n",
    "        #         print(f\"After up4 (with skip connection from inc): {x.shape}\")\n",
    "\n",
    "        logits = self.outc(x)\n",
    "        #         print(f\"Output shape (after OutConv): {logits.shape}\")\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T13:54:27.477174Z",
     "iopub.execute_input": "2024-04-03T13:54:27.477561Z",
     "iopub.status.idle": "2024-04-03T13:54:27.501678Z",
     "shell.execute_reply.started": "2024-04-03T13:54:27.477535Z",
     "shell.execute_reply": "2024-04-03T13:54:27.500710Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from monai.transforms import AsDiscrete\n",
    "class UNetTestModel(pl.LightningModule, HyperparametersMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder_name='resnet50',\n",
    "            encoder_weights='imagenet',\n",
    "            in_channels=1,\n",
    "            classes=14,\n",
    "            #         loss_fn=monai.losses.FocalLoss(use_softmax=True, to_onehot_y=True, include_background=False),\n",
    "            loss_fn=monai.losses.DiceCELoss(softmax=True, lambda_dice=0.85, lambda_ce=0.15, to_onehot_y=True),\n",
    "            #         loss_fn=monai.losses.DiceLoss( to_onehot_y=True),\n",
    "            loss_function='DiceCELoss',\n",
    "            learning_rate=5e-3,\n",
    "            #         train_accuracy_params={'task': \"multiclass\", 'num_classes': 14, 'average': 'macro'},\n",
    "            #         val_accuracy_params={'task': \"multiclass\", 'num_classes': 14, 'average': 'macro'},\n",
    "            #         dice_params={'multiclass': True, 'num_classes': 14, 'average': 'macro'},  \n",
    "            bilinear=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        ###################### model #########################\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=classes,\n",
    "            #             decoder_attention_type='scse',\n",
    "        )\n",
    "        #         self.model = UNet(in_channels, classes, bilinear=bilinear)\n",
    "        ###################### loss ##########################\n",
    "        self.loss_fn = loss_fn\n",
    "        ###################### metrics ######################\n",
    "        #         self.train_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=classes, average='micro', ignore_index=0)\n",
    "        self.val_accuracy_MACRO = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=classes,\n",
    "                                                                       average='macro', ignore_index=0)\n",
    "        self.val_accuracy_micro = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=classes,\n",
    "                                                                       average='micro', ignore_index=0)\n",
    "        self.Dice = torchmetrics.classification.Dice(multiclass=True, num_classes=classes, average='macro',\n",
    "                                                     ignore_index=0)\n",
    "        self.F1 = torchmetrics.classification.MulticlassF1Score(num_classes=classes, average=\"macro\", ignore_index=0)\n",
    "        self.Jaccard = torchmetrics.classification.MulticlassJaccardIndex(num_classes=classes, average=\"macro\",\n",
    "                                                                          ignore_index=0)\n",
    "        #####################################################\n",
    "\n",
    "    #         Outputs Shape: torch.Size([1, 14, 256, 256])\n",
    "    #         Labels Shape: torch.Size([1, 256, 256])\n",
    "    #         Labels Shape After Unsqueeze: torch.Size([1, 1, 256, 256])\n",
    "    #         Predictions Shape: torch.Size([1, 256, 256])\n",
    "\n",
    "    # 定义前向传播\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self.forward(images)\n",
    "        loss = self.loss_fn(outputs, labels.unsqueeze(1))\n",
    "\n",
    "        #         acc = self.train_accuracy(outputs, labels)\n",
    "        #         Dice = self.Dice(outputs, labels)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        #         self.log('train_accuracy', acc, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        #         self.log('train_Dice', Dice, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        #         print(\"val_step going\")\n",
    "        images, labels = batch\n",
    "        outputs = self.forward(images)\n",
    "        loss = self.loss_fn(outputs, labels.unsqueeze(1))\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        #         print(labels_one_hot.shape)\n",
    "        acc_micro = self.val_accuracy_micro(preds, labels)\n",
    "        acc_MACRO = self.val_accuracy_MACRO(preds, labels)\n",
    "        Dice = self.Dice(preds, labels)\n",
    "        F1 = self.F1(preds, labels)\n",
    "        Jaccard = self.Jaccard(preds, labels)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        #         for i,acc in enumerate(acc):\n",
    "        #             self.log(f'val_accuracy_MACRO_{i}', acc, on_step=True, on_epoch=False,logger=True, prog_bar=True)\n",
    "        #         for i,F1 in enumerate(F1):\n",
    "        #             self.log(f'val_F1_{i}', F1, on_step=True, on_epoch=False,logger=True, prog_bar=True)\n",
    "        self.log('val_accuracy_micro', acc_micro, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_accuracy_MACRO', acc_MACRO, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_F1', F1, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_Dice', Dice, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "        self.log('val_Jaccard', Jaccard, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n",
    "\n",
    "    #     def test_step(self, batch, batch_idx):\n",
    "    #         images, labels = batch\n",
    "    #         outputs = self.forward(images)\n",
    "    #         loss = self.loss_fn(outputs, labels.unsqueeze(1))\n",
    "\n",
    "    #         preds = torch.argmax(outputs, dim=1)\n",
    "    #         acc_MACRO = self.val_accuracy_MACRO(preds, labels)  # 注意: 在测试阶段，我们仍然可以使用val_accuracy_MACRO\n",
    "    #         Dice = self.Dice(preds, labels)\n",
    "    #         self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    #         self.log('test_accuracy', acc_MACRO, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    #         self.log('test_Dice', Dice, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    #         # 这里没有wandb.log调用，因为PyTorch Lightning的self.log已经足够记录所有指标\n",
    "\n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure, **kwargs):\n",
    "        # 调用优化器的step方法前执行自定义操作\n",
    "        # 比如实现学习率热启动\n",
    "        if self.trainer.global_step < 25:\n",
    "            lr_scale = min(1.0, float(self.trainer.global_step + 1) / 25)\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg[\"lr\"] = lr_scale * self.hparams.learning_rate\n",
    "        # 调用优化器的step方法来更新模型参数\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        #         scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9, verbose=True)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.000001, last_epoch=-1)\n",
    "        #         print(self.hparams.learning_rate)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch',  # 指定更新学习率的间隔单位为'epoch'\n",
    "                'frequency': 1,  # 每个epoch更新一次学习率\n",
    "            }\n",
    "        }"
   ],
   "metadata": {
    "_uuid": "ac36333a-0d4f-494b-a95c-889fc8ca64d9",
    "_cell_guid": "e855577b-fc8c-4409-b4d6-0f82ee37f1d3",
    "execution": {
     "iopub.status.busy": "2024-04-03T13:54:32.093379Z",
     "iopub.execute_input": "2024-04-03T13:54:32.093710Z",
     "iopub.status.idle": "2024-04-03T13:54:32.116348Z",
     "shell.execute_reply.started": "2024-04-03T13:54:32.093686Z",
     "shell.execute_reply": "2024-04-03T13:54:32.115386Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (Opt) Hyper Params Check"
   ],
   "metadata": {
    "_uuid": "7357d769-1c7b-4ae0-b717-68fe4d9524bc",
    "_cell_guid": "f00537a2-4837-4a41-94fe-819c9ce7b959",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = UNetTestModel()\n",
    "print(summary(model, input_size=(1, 1, 256, 256)))\n",
    "print(model.hparams)"
   ],
   "metadata": {
    "_uuid": "54a3656f-6ee2-41bb-92cc-2f278e3ed7d7",
    "_cell_guid": "e6d612dd-14b3-4d64-960e-78b581b1d7e3",
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2024-04-03T13:54:36.622957Z",
     "iopub.execute_input": "2024-04-03T13:54:36.623325Z",
     "iopub.status.idle": "2024-04-03T13:54:40.435160Z",
     "shell.execute_reply.started": "2024-04-03T13:54:36.623296Z",
     "shell.execute_reply": "2024-04-03T13:54:40.433977Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (Opt) Pre-Train Test"
   ],
   "metadata": {
    "_uuid": "7e5a9389-57b6-4a07-b428-b41fcc987525",
    "_cell_guid": "de47c7ee-1eee-4ee1-93f6-d6b43df86981",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_module = MOADataModule(data_dir=data_dir, batch_size=1)\n",
    "# avail test\n",
    "model = UNetTestModel()\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "############################################## fastrun ###################################################\n",
    "trainer = pl.Trainer(max_epochs=20,\n",
    "                     fast_dev_run=True,\n",
    "                     #                      callbacks=[lr_monitor, ValidationCallback()],\n",
    "                     #                      check_val_every_n_epoch=10, \n",
    "                     )\n",
    "trainer.fit(model, datamodule=data_module)"
   ],
   "metadata": {
    "_uuid": "3c026544-ec35-408c-9c4a-8840ba0d8202",
    "_cell_guid": "37e59d03-78db-479e-954e-7e8fb28a80a3",
    "execution": {
     "iopub.status.busy": "2024-04-03T13:55:00.462175Z",
     "iopub.execute_input": "2024-04-03T13:55:00.463086Z",
     "iopub.status.idle": "2024-04-03T13:55:02.386127Z",
     "shell.execute_reply.started": "2024-04-03T13:55:00.463054Z",
     "shell.execute_reply": "2024-04-03T13:55:02.384569Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_module = MOADataModule(data_dir=data_dir, batch_size=1)\n",
    "# learnability test\n",
    "wandb_logger_test = WandbLogger()\n",
    "# # 初始化Trainer，设置overfit_batches来过拟合一小部分数据\n",
    "# lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "test_trainer = pl.Trainer(overfit_batches=1,\n",
    "                          logger=wandb_logger_test,\n",
    "                          #                           callbacks=[lr_monitor, ValidationCallback()], \n",
    "                          check_val_every_n_epoch=1)\n",
    "\n",
    "# # 或者，使用10个批次的数据来过拟合\n",
    "# test_trainer = pl.Trainer(overfit_batches=10, logger=wandb_logger_test)\n",
    "\n",
    "# 运行训练\n",
    "test_trainer.fit(model, datamodule=data_module)\n",
    "wandb.finish()"
   ],
   "metadata": {
    "_uuid": "273bd454-c583-441a-8b86-d5b109f13028",
    "_cell_guid": "4417d2cf-aade-490c-9cf2-4aed7f9bb6f0",
    "execution": {
     "iopub.status.busy": "2024-04-03T08:09:24.646722Z",
     "iopub.execute_input": "2024-04-03T08:09:24.647589Z",
     "iopub.status.idle": "2024-04-03T08:10:22.60761Z",
     "shell.execute_reply.started": "2024-04-03T08:09:24.647554Z",
     "shell.execute_reply": "2024-04-03T08:10:22.606497Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sweeps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'},\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'min': 0.0001,\n",
    "            'max': 0.1},\n",
    "        'batch_size': {\n",
    "            'values': [16, 32, 64]}\n",
    "    }\n",
    "}\n",
    "wandb_logger = WandbLogger()\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"test sweeps2\")\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "\n",
    "def sweep_train():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        model = UNetTestModel(\n",
    "            learning_rate=config.learning_rate,\n",
    "            #             batch_size=config.batch_size,\n",
    "            # 其他参数...\n",
    "        )\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=150,\n",
    "            callbacks=[lr_monitor, ValidationCallback()],\n",
    "            logger=wandb_logger,\n",
    "            #             check_val_every_n_epoch=10,\n",
    "            # 其他设置...\n",
    "        )\n",
    "        data_module = MOADataModule(data_dir=data_dir, batch_size=config.batch_size)\n",
    "        trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, function=sweep_train, count=10)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-31T04:44:01.362615Z",
     "iopub.execute_input": "2024-03-31T04:44:01.36358Z",
     "iopub.status.idle": "2024-03-31T04:45:17.412101Z",
     "shell.execute_reply.started": "2024-03-31T04:44:01.363541Z",
     "shell.execute_reply": "2024-03-31T04:45:17.410888Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lightning Style Formal Test"
   ],
   "metadata": {
    "_uuid": "8aa9f836-18b6-4afe-8a97-02aa78f1c528",
    "_cell_guid": "db51d23f-6157-4418-9399-1403d782d90e",
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "# 假设你已经定义了 LiTSDataModule\n",
    "data_module = MOADataModule(data_dir=data_dir, batch_size=16)\n",
    "# 初始化模型和训练器\n",
    "model = UNetTestModel(bilinear=False)\n",
    "\n",
    "# wandb_logger = WandbLogger(project=\"SMU MOA\", name=\"ResUNetPP50_monaiDiceCELoss_Max150\")\n",
    "wandb_logger = WandbLogger(project=\"UNet Baseline\", name=\"Origin_UNet_noAtt_Max150_DiceCELoss\")\n",
    "# wandb_logger = WandbLogger()\n",
    "\n",
    "\n",
    "trainer = Trainer(max_epochs=150,\n",
    "                  #                      fast_dev_run=True, \n",
    "                  logger=wandb_logger,\n",
    "                  #                   callbacks=[lr_monitor, ValidationCallback()],\n",
    "                  callbacks=[lr_monitor],\n",
    "                  log_every_n_steps=1,\n",
    "                  check_val_every_n_epoch=1,\n",
    "                  #                   precision='16-mixed',\n",
    "                  )\n",
    "\n",
    "# 创建 Tuner 对象并运行学习率查找\n",
    "# tuner = Tuner(trainer)\n",
    "# lr_finder = tuner.lr_find(model, datamodule=data_module)\n",
    "\n",
    "# # 可视化找到的学习率\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# display(fig)\n",
    "\n",
    "# # 将建议的学习率设置给模型\n",
    "# new_lr = lr_finder.suggestion()\n",
    "# model.hparams.learning_rate = new_lr\n",
    "\n",
    "\n",
    "# 注意：在此处，你不需要手动更新 DataLoader 的批量大小\n",
    "# 因为 tuner.scale_batch_size 方法已经更新了 LiTSDataModule 中的 batch_size\n",
    "# 你可以检查更新后的批量大小\n",
    "# tuner.scale_batch_size(model, datamodule=data_module, mode=\"power\")\n",
    "# print(f\"Updated batch size: {data_module.batch_size}\")\n",
    "\n",
    "# 使用更新后的学习率继续训练\n",
    "trainer.fit(model, datamodule=data_module)"
   ],
   "metadata": {
    "_uuid": "0049db84-14fe-45a1-aef2-75921b97a7c0",
    "_cell_guid": "02f8ebdf-9845-4e4b-9439-0fbefbf50fbd",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-03T08:11:35.473532Z",
     "iopub.execute_input": "2024-04-03T08:11:35.474292Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 确保模型处于评估模式\n",
    "model.eval()\n",
    "print(\"eval activated\")\n",
    "\n",
    "\n",
    "def predict_and_log_images(num_samples=2):\n",
    "    # 假设 test_loader 和 model 已经定义好了，并且 model 已经移动到了适当的设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    test_loader = data_module.test_dataloader()\n",
    "\n",
    "    # 生成随机索引\n",
    "    indices = torch.randperm(len(test_loader.dataset))[:num_samples]\n",
    "    # 调整subplot的大小\n",
    "    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))  # 每个样本显示3张图（原图、真实掩码、预测掩码）\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = test_loader.dataset[idx]\n",
    "        image = image.unsqueeze(0).to(device)  # 添加batch维度并移动到设备\n",
    "        mask = mask.squeeze()  # 移除batch维度（如果有的话）\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(image)\n",
    "            prediction = torch.argmax(pred, dim=1).cpu()  # 获取预测类别并移回CPU\n",
    "\n",
    "        # 显示原始图像\n",
    "        axs[i, 0].imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "        axs[i, 0].set_title(f'Original Image {i + 1}')\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # 显示Ground Truth\n",
    "        axs[i, 1].imshow(mask.cpu().numpy(), cmap='gray')\n",
    "        axs[i, 1].set_title(f'True Mask {i + 1}')\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        # 显示预测掩码\n",
    "        axs[i, 2].imshow(prediction[0].numpy(), cmap='gray')\n",
    "        axs[i, 2].set_title(f'Predicted Mask {i + 1}')\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #     plt.close(fig)  # 防止在notebook中显示图像\n",
    "    return fig"
   ],
   "metadata": {
    "_uuid": "e7c92b10-d357-49d3-a914-e4db61774d96",
    "_cell_guid": "121e8a6e-fabd-45ac-9572-30eb13c443d3",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-03T07:40:30.575698Z",
     "iopub.execute_input": "2024-04-03T07:40:30.576539Z",
     "iopub.status.idle": "2024-04-03T07:40:30.593137Z",
     "shell.execute_reply.started": "2024-04-03T07:40:30.576498Z",
     "shell.execute_reply": "2024-04-03T07:40:30.591917Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 循环十次，每次都记录图像\n",
    "for _ in range(10):\n",
    "    fig = predict_and_log_images(num_samples=2)\n",
    "    wandb.log({\"Predicted Images\": wandb.Image(fig)})"
   ],
   "metadata": {
    "_uuid": "ca2de490-a6d3-442b-ae6f-6ec9c9ed6d70",
    "_cell_guid": "b7ef133e-78ff-4942-b372-18d4909f3531",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-03T07:40:32.977358Z",
     "iopub.execute_input": "2024-04-03T07:40:32.97822Z",
     "iopub.status.idle": "2024-04-03T07:40:50.68459Z",
     "shell.execute_reply.started": "2024-04-03T07:40:32.978189Z",
     "shell.execute_reply": "2024-04-03T07:40:50.683516Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results = trainer.test(dataloaders=data_module.val_dataloader())\n",
    "print(results)"
   ],
   "metadata": {
    "_uuid": "3b5689d1-ff8c-4930-88fa-c9dfa38f5195",
    "_cell_guid": "5725cdac-948a-4953-8a35-18186f67bdb1",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-03T05:31:50.942335Z",
     "iopub.execute_input": "2024-04-03T05:31:50.942717Z",
     "iopub.status.idle": "2024-04-03T05:31:51.108384Z",
     "shell.execute_reply.started": "2024-04-03T05:31:50.942684Z",
     "shell.execute_reply": "2024-04-03T05:31:51.106887Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 创建一个新的Artifact，指定其类型为'model'和Artifact的名称\n",
    "artifact = wandb.Artifact('ResUNetPP50_monaiDiceCELoss_Max150', type='model')\n",
    "artifact.add_file('/kaggle/working/SMU MOA/vq9tunx5/checkpoints/epoch=149-step=4950.ckpt')\n",
    "\n",
    "# 保存Artifact到wandb\n",
    "wandb.log_artifact(artifact)"
   ],
   "metadata": {
    "_uuid": "51fc1ba5-2cb0-4d6c-9869-a2818e01d7a2",
    "_cell_guid": "ddb49941-070c-4aba-8d7b-d77746b33eea",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-01T03:25:52.087368Z",
     "iopub.execute_input": "2024-04-01T03:25:52.088157Z",
     "iopub.status.idle": "2024-04-01T03:25:54.622164Z",
     "shell.execute_reply.started": "2024-04-01T03:25:52.088116Z",
     "shell.execute_reply": "2024-04-01T03:25:54.621037Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "_uuid": "b406957a-23ba-4bc5-abe5-2f222a2093aa",
    "_cell_guid": "861d04f7-0fb1-4f03-917b-199d6f54d36b",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-04-03T07:51:36.429134Z",
     "iopub.execute_input": "2024-04-03T07:51:36.429548Z",
     "iopub.status.idle": "2024-04-03T07:51:36.434822Z",
     "shell.execute_reply.started": "2024-04-03T07:51:36.429512Z",
     "shell.execute_reply": "2024-04-03T07:51:36.433724Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
